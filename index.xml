<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>IO42 Learning to Learn</title>
    <link>https://io42.space/</link>
      <atom:link href="https://io42.space/index.xml" rel="self" type="application/rss+xml" />
    <description>IO42 Learning to Learn</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2022 Iaroslav Omelianenko</copyright><lastBuildDate>Sat, 10 Aug 2024 16:15:00 +0000</lastBuildDate>
    <image>
      <url>https://io42.space/img/portrait.jpg</url>
      <title>IO42 Learning to Learn</title>
      <link>https://io42.space/</link>
    </image>
    
    <item>
      <title>Design of cluster-computing architecture to improve training speed of the Neuroevolution algorithm</title>
      <link>https://io42.space/publication/icict2024/</link>
      <pubDate>Sat, 10 Aug 2024 16:15:00 +0000</pubDate>
      <guid>https://io42.space/publication/icict2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Artificial swarm intelligence</title>
      <link>https://io42.space/publication/pci1028-0979-2024-3-7/</link>
      <pubDate>Thu, 04 Jul 2024 15:28:14 +0200</pubDate>
      <guid>https://io42.space/publication/pci1028-0979-2024-3-7/</guid>
      <description></description>
    </item>
    
    <item>
      <title>UkrPROG 2024 paper presentation</title>
      <link>https://io42.space/talk/ukrprog2024/</link>
      <pubDate>Tue, 14 May 2024 10:15:00 -0300</pubDate>
      <guid>https://io42.space/talk/ukrprog2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ICICT 2024 paper presentation</title>
      <link>https://io42.space/talk/icict2024/</link>
      <pubDate>Thu, 22 Feb 2024 16:15:00 -0800</pubDate>
      <guid>https://io42.space/talk/icict2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Simulation of the Autonomous Maze Navigation using the NEAT Algorithm</title>
      <link>https://io42.space/publication/pp2023.04.076/</link>
      <pubDate>Fri, 01 Dec 2023 15:28:14 +0200</pubDate>
      <guid>https://io42.space/publication/pp2023.04.076/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Machine Learning and the City: Applications in Architecture and Urban Design</title>
      <link>https://io42.space/publication/machine-learning-and-the-city/</link>
      <pubDate>Wed, 01 Jun 2022 17:38:33 +0200</pubDate>
      <guid>https://io42.space/publication/machine-learning-and-the-city/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Hands-On Neuroevolution With Python</title>
      <link>https://io42.space/publication/hands-on-neuroevolution-with-python/</link>
      <pubDate>Wed, 01 Jan 2020 17:38:33 +0200</pubDate>
      <guid>https://io42.space/publication/hands-on-neuroevolution-with-python/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Artificial Swarm Intelligence and Cooperative Robotic Systems</title>
      <link>https://io42.space/publication/preprints201901.0282/</link>
      <pubDate>Tue, 05 Feb 2019 15:05:37 +0200</pubDate>
      <guid>https://io42.space/publication/preprints201901.0282/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Creation of Autonomous Artificial Intelligent Agents using Novelty Search method of fitness function optimization</title>
      <link>https://io42.space/post/creation-aaia-using-novelty-search/</link>
      <pubDate>Thu, 06 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://io42.space/post/creation-aaia-using-novelty-search/</guid>
      <description>&lt;p&gt;For billions of years of evolution, biological intelligent agents have mastered the power to find optimal solutions in deceptive environments that we encounter in our daily interactions with the real world. We can easy navigate themselves through the maze of a big city subways and roadways. But for artificial intelligent systems, this is too difficult to be easily solved using the optimal computing resources. This is especially true for offline autonomous agents that are not backed by &lt;em&gt;super power of cloud servers&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The main problem here is related to the fact that reliable maze navigation requires the development of a solution in an environment having many traps with strong local optima of fitness function. Such traps are represented as cul-de-sacs that are close to the final destination, but that can not be escaped without a step back, away from the ultimate goal (at least temporary). In such environments, objective-based solvers basically can not find optimal solution or any solution at all, because they do not have the necessary internal machinery for committing the leap-of-faith and move backward from the target in order to eventually find a way out.&lt;/p&gt;
&lt;p&gt;The objective-based solvers depends on the best attempts of their designers to assess the operating environment and develop a better way to achieve the ultimate goal. But, as it happens in the real world, preliminary assumptions often can not account for all the traps on the way to the goal because of the extreme complexity of the environment settings. And even in simple artificial environments, such as maze navigation, it often happens that objective-based solvers can not find the optimal solution within the &lt;em&gt;adequate execution time and computational resources allocation&lt;/em&gt;. But for successful autonomous execution in real world environments, it is critically important to create Intelligent Agents capable of quickly finding a solution with minimal computational load.&lt;/p&gt;
&lt;h2 id=&#34;experiment-overview&#34;&gt;EXPERIMENT OVERVIEW&lt;/h2&gt;
&lt;p&gt;In the experiment we studied how Novelty Search (NS)&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; method of fitness function optimization performs compared to traditional objective-based ones for unsupervised training of Artificial Intelligent Agents to do spatial navigation in complex maze environment. The main idea behind NS optimization is to rather look for novel outcomes in the search space than the distance to the final objective: the maze exit. The Novelty Search assigns higher fitness values to the Intelligent Agent capable to find the most novel solution among all previous tries. Despite its ignorance to the final objective the NS happens to be extremely effective optimization method capable of breeding AAIA, which crack deceptive real-world tasks even in the realms where traditional objective-based methods have failed completely. The main assumption about what makes this possible, is that in order to reach final goal, AAIA must find several intermediate goals (stepping stones) which in most cases do not resemble the ultimate objective. Sometimes Intelligent Agent must step back to avoid deceptive traps. By doing this it will see a decrease in value of objective-based fitness function for a moment but will get a better outcomes in the future. This is one of the fundamental properties of the real-world environment that the exact route to the final objective in most cases can not be predicted in advance, and all intermediate stepping stones should be found by taking the path.&lt;/p&gt;
&lt;p&gt;The Novelty Search optimization seems like a natural fit for Neuro-evolution family of genetic algorithms producing elegant custom Artificial Neural Networks (ANNs). In the experiment we combined NS with Neuroevolution of Augmented Topologies algorithm&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; which efficiently evolve ANNs through complexification by augmenting its topologies.&lt;/p&gt;
&lt;p&gt;More details about NEAT algorithm implementation can be found in my previous article: ‘Neuroevolution — evolving Artificial Neural Networks topology from the scratch’&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h4 id=&#34;-the-maze-solver-agent-configuration&#34;&gt;&amp;gt; The Maze Solver Agent Configuration&lt;/h4&gt;
&lt;p&gt;Autonomous Artificial Intelligent Agent, designed to solve the maze, has ten input sensors that allow collecting information about the environment and two output effectors controlling its movements through the maze (see &lt;em&gt;Figure 1&lt;/em&gt;). The final objective of the agent is to go through the maze and find a way out.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;maze-agent.png&#34; data-caption=&#34;The configuration schema of the maze agent with input sensors plot&#34;&gt;
&lt;img data-src=&#34;maze-agent.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The configuration schema of the maze agent with input sensors plot
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The input sensors are: six range finders that indicate the distance to the nearest obstacle (blue arrows) and four pie-slice radar sensors (slices of red circle) that act as a compass towards the goal (maze exit), activating when a line from the goal to the center of the agent falls within the pie-slice. The green-yellow arrow in the center points to the movement direction of the agent.&lt;/p&gt;
&lt;p&gt;The agent is also equipped with two effectors producing a forces that respectively turn and propel the robot, i.e. change its linear and angular velocity.&lt;/p&gt;
&lt;h4 id=&#34;-seed-genome-configuration&#34;&gt;&amp;gt; Seed Genome Configuration&lt;/h4&gt;
&lt;p&gt;The configuration of the seed genome of the solver agent can be summarized as follows (see &lt;em&gt;Figure 2&lt;/em&gt;):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ten input (sensor) neurons (blue): six for range finders [RIGHT, FRONT-RIGHT, FRONT, FRONT-LEFT, LEFT, BACK] plus four for slice radar sensors with 45 degree FOV [FRONT, LEFT, BACK, RIGHT]&lt;/li&gt;
&lt;li&gt;two output (effectors) neurons (red): angular (neuron #13) and linear (neuron #14) velocity controlling effectors&lt;/li&gt;
&lt;li&gt;one hidden neuron (#12) to introduce non linearity (green)&lt;/li&gt;
&lt;li&gt;one bias neuron (#1) to avoid zero saturation when input neurons is not activated (yellow)&lt;/li&gt;
&lt;/ul&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;seed-genome.png&#34; data-caption=&#34;The seed genome configuration&#34;&gt;
&lt;img data-src=&#34;seed-genome.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The seed genome configuration
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The input neurons has following numbers on the diagram above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Range Finders: #2 — RIGHT, #3 — FRONT-RIGHT, #4 — FRONT, #5 — FRONT-LEFT, #6 — LEFT, #7 — BACK&lt;/li&gt;
&lt;li&gt;Radar Sensors: #8 — FRONT, #9 — LEFT, #10 — BACK, #11 — RIGHT&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;-the-novelty-search-metric-definition-for-a-maze-environment&#34;&gt;&amp;gt; The Novelty Search metric definition for a maze environment&lt;/h4&gt;
&lt;p&gt;The &lt;em&gt;Novelty Search optimization&lt;/em&gt; method is based on novelty metric calculation for each solver agent after performing a certain number of time steps in simulation of maze navigation for that agent. The novelty metric biases the search in a fundamentally different way than the &lt;em&gt;objective-based&lt;/em&gt; fitness function (which depends only on the distance from the agent to the exit) and determines the behavior-space through which the search will be performed. Therefore, since what is important in the maze, this is where the solving agent ends navigation, then for the maze domain, the behavior of a navigator is defined as &lt;em&gt;its final position&lt;/em&gt;. The novelty metric then maximizes the N-nearest neighbor distance&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; between the final positions of all known solving agents, i.e. the most distant agent will have the greatest score of the novelty metric.&lt;/p&gt;
&lt;p&gt;The effect of this novelty metric is to reward the solver agent for ending in a place where none have ended before and the method of traversal is ignored. This measure reflects that what is important, is to reach a certain location (i.e. the goal) rather than the method of locomotion. Thus, although the novelty metric has no knowledge of the ultimate goal, a solution that reaches the goal can appear novel. In addition, the comparison between fitness-based and novelty-based search is fair because both scores are calculated only based on the distance of the final position of the agent from other points.&lt;/p&gt;
&lt;h2 id=&#34;experiment-results&#34;&gt;EXPERIMENT RESULTS&lt;/h2&gt;
&lt;p&gt;As for deceptive environments we choose two types of maze environments with different complexity as was recommended in &lt;em&gt;this research&lt;/em&gt;&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;: medium and hard maze. The maze configurations was designed in such a way as to create many cul-de-sacs with strong local optima, deceiving the objective-based optimization methods.&lt;/p&gt;
&lt;h3 id=&#34;the-medium-complexity-maze-environment&#34;&gt;The Medium Complexity Maze Environment&lt;/h3&gt;
&lt;p&gt;The first experiment to establish baseline performance metric was performed using &lt;strong&gt;maze configuration of medium complexity&lt;/strong&gt;. The Novelty Search optimization was combined with Neuro-Evolution of Augmented Topologies algorithm which use genetic neuro-evolution process to create a population of organisms capable of solving a maze. We also compared its performance with the objective-based optimization method for the NEAT algorithm, where fitness function optimization was dependent on how close final destination of produced organism is from the exit of the maze.&lt;/p&gt;
&lt;p&gt;The final performance metric of each Autonomous Agent created for both optimization methods depends only on how close to the maze exit is the final destination of the solver after $400$ stimulation steps. Thus, despite the various methods of fitness function optimization, the final results can be compared for both methods. Each experimental trial was performed with $2000$ epochs of evolution or until a winner is found.&lt;/p&gt;
&lt;h4 id=&#34;-novelty-search-optimization&#34;&gt;&amp;gt; Novelty Search Optimization&lt;/h4&gt;
&lt;p&gt;Applying Novelty Search based optimization it was possible to get the winner in &lt;strong&gt;10 form 10&lt;/strong&gt; trials with optimal genome found approximately within $50$ generations. An Artificial Neural Network produced by an organism with a near optimal genome has $1$ neurons with only three hidden units, i.e. it was capable of growing two additional units compared to the above-mentioned seed genome (see &lt;a href=&#34;#seed-genome-configuration&#34;&gt;Figure 2&lt;/a&gt;). And it is able to control maze solver agent with a spatial error of about $1.9%$ for targeting the exit of the maze.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;medium-maze-NS-winner.png&#34; data-caption=&#34;The medium maze winner&amp;rsquo;s genome when Novelty Search optimization method applied&#34;&gt;
&lt;img data-src=&#34;medium-maze-NS-winner.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The medium maze winner&amp;rsquo;s genome when Novelty Search optimization method applied
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Among with the two additional hidden units (neurons), the recurrent link was developed at the output neuron #13 (&lt;em&gt;angular velocity effector&lt;/em&gt;) — see &lt;em&gt;Figure 3&lt;/em&gt;. The recurrent link at this output neuron appears to be of great importance, since it was introduced in each configuration of the winner’s genome generated in each test trial. Such a consistent pattern seems pretty reasonable for the neuron #13, because it affects the agent’s steering and requires learning more complicated behavior compared to the neuron #14 (&lt;em&gt;linear velocity control&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;It is also interesting to consider the hidden neuron #91, which seemingly have learned the complex behavior of the steering to the exit of the maze when it is discovered to the right or behind the agent. We&amp;rsquo;ve made such assumptions because of its connections with input sensors #2, #7 (range finders: RIGHT, BACK) and #10, #11 (radar sensors: BACK, RIGHT).&lt;/p&gt;
&lt;p&gt;The hidden neuron #293 connected with input sensor #11 (radar sensor: RIGHT), has learned to influence the steering of the agent in the direction of the exit of the maze, since most of the time the exit is on the right bottom relative to the agent.&lt;/p&gt;
&lt;p&gt;The hidden neuron #12 which is introduced in &lt;a href=&#34;#seed-genome-configuration&#34;&gt;seed genome&lt;/a&gt; operates as main control-and-relay switch relaying signals from sensors and other hidden neurons to the effectors (neurons #13, #14).&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;medium-maze-NS.png&#34; data-caption=&#34;The color coded final positions of NS maze solvers for medium maze environment&#34;&gt;
&lt;img data-src=&#34;medium-maze-NS.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The color coded final positions of NS maze solvers for medium maze environment
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;On the &lt;em&gt;Figure 4&lt;/em&gt; presented a diagram of the maze solving simulation by solver agents controlled by ANNs, derived from the genomes of all organisms introduced into the population until a winner is found. Agents are coded by color depending on which species the source organism belongs to. The fitness of agent is measured as the relative distance between its final destination and maze exit after running simulation for certain number of time steps (&lt;em&gt;$400$ in our setup&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;initial agent position is at the top-left corner&lt;/em&gt; marked with green circle and &lt;em&gt;maze exit at the bottom-right&lt;/em&gt; marked with red circle.&lt;/p&gt;
&lt;p&gt;The upper plot shows the final destinations of the most fit agents ($fitness &amp;gt;= 0.8$), and the lower plot - the rest. The results are presented for an experimental trial producing the configuration of the winner genome depicted at &lt;em&gt;Figure 3&lt;/em&gt;. The total number of species created at that trial is $32$, with only $8$ becoming the most fit ones ($fitness &amp;gt;= 0.8$).&lt;/p&gt;
&lt;h4 id=&#34;-objective-based-optimization&#34;&gt;&amp;gt; Objective-Based Optimization&lt;/h4&gt;
&lt;p&gt;Applying objective-based optimization, it was possible to create the winners capable of solving medium maze configuration in &lt;strong&gt;9 from 10&lt;/strong&gt; trials. But the configuration of the winner&amp;rsquo;s genome in most cases was not so elegant and energy efficient, as with above-mentioned Novelty Search optimization.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;medium-maze-objective-winner.png&#34; data-caption=&#34;The medium maze winner&amp;rsquo;s genome when objective-based fitness function optimization method applied&#34;&gt;
&lt;img data-src=&#34;medium-maze-objective-winner.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The medium maze winner&amp;rsquo;s genome when objective-based fitness function optimization method applied
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;After $248$ generations, it was found near optimal configuration of the winner&amp;rsquo;s genome (see &lt;em&gt;Figure 5&lt;/em&gt;), capable of guiding the maze solving agent through the medium-complexity maze and reach the exit of the maze with spatial error about $1.8%$. The artificial neural network produced by this genome has $22$ units (neurons) with nine hidden neurons for modeling complex learned behavior.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;medium-maze-objective.png&#34; data-caption=&#34;The color coded final positions of objective-based maze solvers for medium maze environment&#34;&gt;
&lt;img data-src=&#34;medium-maze-objective.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The color coded final positions of objective-based maze solvers for medium maze environment
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Comparing the objective-based simulation plot (&lt;em&gt;Figure 6&lt;/em&gt;) with the similar for simulation based on Novelty Search optimization, it can be seen that agents final destinations are distributed less evenly through the maze space. Another interesting point is that most fit agents were &lt;em&gt;less exploratory&lt;/em&gt;, moving mainly along the maze walls towards the local fitness optima. This behavior resulted in more generations needed to produce the winner on average, as well as completely failed trials.&lt;/p&gt;
&lt;h3 id=&#34;the-hard-complexity-maze-environment&#34;&gt;The Hard Complexity Maze Environment&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;hard maze configuration&lt;/strong&gt; introduces additional complexity, emphasizing the idiosyncrasies of the objective-based optimization method. This requires a bit of strategic thinking, which sometimes allows the agent to deviate from the seemingly optimal places (with high local fitness function values) to finally find the guiding path through the maze. The ability of Novelty Search optimization to mimic mentioned strategic reasoning due to its inherent ability to find all the promising areas of the search space has made it an absolute champion with this experiment.&lt;/p&gt;
&lt;h4 id=&#34;-novelty-search-optimization-1&#34;&gt;&amp;gt; Novelty Search Optimization&lt;/h4&gt;
&lt;p&gt;The &lt;em&gt;Novelty Search&lt;/em&gt; optimization method, produced solving agents capable to solve the hard maze in &lt;strong&gt;10 from 10&lt;/strong&gt; trials. The power of NS method led to the finding of winning solvers within up to $100$ generations in the maze environment of both: medium and hard complexity. Which marks NS as a highly effective optimization method for creating Autonomous Artificial Intelligent Agents capable of complex spatial navigation.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;hard-maze-NS-winner.png&#34; data-caption=&#34;The hard maze winner&amp;rsquo;s genome when Novelty Search optimization method applied&#34;&gt;
&lt;img data-src=&#34;hard-maze-NS-winner.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The hard maze winner&amp;rsquo;s genome when Novelty Search optimization method applied
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;After $109$ generations of populations of organisms, the near optimal configuration of the winner&amp;rsquo;s genome was found (see &lt;em&gt;Figure 7&lt;/em&gt;). The winner is able to guide the agent through the hard maze environment and approach the exit with a spatial error $2.5%$. The Artificial Neural Network produced by this genome has only $17$ units (neurons) with four hidden neurons for &lt;em&gt;modeling complex learned behavior&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;It is interesting to note that recurrent link on the output neuron #13 (angular velocity effector) was &lt;em&gt;routed through two hidden neurons&lt;/em&gt; compared with the medium maze, where the neuron #13 was simply linked to itself. This may result in more complex behavior learned, especially taking into account that link passes through the neuron #42, affected by the range finder: LEFT and the radar: BACK. The neuron #42 is also affected by connection to the neuron #643 (affected by the range finder: LEFT). As a result, we can assume that it learned how to steer the agent when the exit of the maze is behind, and the wall is on the left, i.e. follow the left wall, moving forward.&lt;/p&gt;
&lt;p&gt;Another important point to consider is about possible learned behavior encoded in the hidden neuron #297, which is affected by input range finder sensors detecting distance to obstacles in the RIGHT and FRONT direction. Considering the maze configuration, we can assume that this neuron learned to avoid the left chamber&amp;rsquo;s trap, where an extremely strong local maximum of the fitness function was introduced (based on the distance to the exit of the maze).&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;hard-maze-NS.png&#34; data-caption=&#34;The color coded final positions of NS maze solvers for hard maze environment&#34;&gt;
&lt;img data-src=&#34;hard-maze-NS.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The color coded final positions of NS maze solvers for hard maze environment
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Because of the inherent complexity of the hard maze environment, only one species from $35$ was able to beget genome with fitness greater than $0.8$. This genome is also the winner able to produce control ANN successfully guiding solver agent to the exit of the maze. But, as can be seen from the &lt;em&gt;Figure 8&lt;/em&gt;, there is a high probability that as the number of simulation steps increases, a larger number of species will be able to hit the fitness threshold ($0.8$).&lt;/p&gt;
&lt;h4 id=&#34;-objective-based-optimization-1&#34;&gt;&amp;gt; Objective-Based Optimization&lt;/h4&gt;
&lt;p&gt;The &lt;em&gt;objective-based&lt;/em&gt; fitness function optimization method &lt;em&gt;completely failed to create any successful solver agent within all 10 experiment trials&lt;/em&gt;. In some trials, it was able to create AAIAs, almost finding the exit of the maze, but it seems that many more simulation steps are required to eventually produce the winner genome, which makes it &lt;em&gt;too computationally expensive&lt;/em&gt;.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;hard-maze-objective.png&#34; data-caption=&#34;The color coded final positions of NS maze solvers for hard maze environment&#34;&gt;
&lt;img data-src=&#34;hard-maze-objective.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The color coded final positions of NS maze solvers for hard maze environment
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The &lt;em&gt;Figure 9&lt;/em&gt; depicts the most successful trials of the hard maze solvers with objective-based optimization of the fitness function. Looking at it, it can be seen that most of the final destinations of the Intelligent Agents were trapped in deceptive cul-de-sacs, blocking them from further exploration of the maze environment search space.&lt;/p&gt;
&lt;h2 id=&#34;discussion&#34;&gt;DISCUSSION&lt;/h2&gt;
&lt;p&gt;As shown by our experimental data, the &lt;em&gt;Novelty Search method&lt;/em&gt; of fitness function optimization, when the fitness of the agent is based on the novelty of the solution that it was able to find, significantly outperforms traditional objective-based optimization and was even able to solve the navigation task when the traditional method failed completely.&lt;/p&gt;
&lt;p&gt;We believe that &lt;em&gt;Novelty Search optimization&lt;/em&gt; can be successfully applied to create optimal solving agents in many areas where strong deceptive local optima of fitness function prevents traditional objective-based methods from finding optimal or any solutions at all.&lt;/p&gt;
&lt;p&gt;The full source code of the experiment implemented in GoLang: &lt;a href=&#34;https://github.com/yaricom/goNEAT_NS&#34;&gt;https://github.com/yaricom/goNEAT_NS&lt;/a&gt;. Please refer to it for more details about experiment particulars.&lt;/p&gt;
&lt;p&gt;The associated research project can be found at ResearchGate: &lt;a href=&#34;https://www.researchgate.net/project/Novelty-Search-optimization-for-NeuroEvolution&#34;&gt;https://www.researchgate.net/project/Novelty-Search-optimization-for-NeuroEvolution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The author&amp;rsquo;s NEAT algorithm implementation in the GO language is also shared through NEAT software catalog, hosted by Evolutionary Complexity (EPlex) Research Group at the University of Central Florida: &lt;a href=&#34;http://eplex.cs.ucf.edu/neat_software/&#34;&gt;http://eplex.cs.ucf.edu/neat_software/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Special thanks to &lt;a href=&#34;http://www.cs.ucf.edu/~kstanley/&#34;&gt;Dr. Kenneth O. Stanley&lt;/a&gt; for advises and sharing the NEAT algorithm details.&lt;/p&gt;
&lt;h2 id=&#34;future-work&#34;&gt;FUTURE WORK&lt;/h2&gt;
&lt;p&gt;We consider the development of modular AI systems based on ensembles of highly optimized compact Neural Networks. Our goal is to create compact utility NN blocks that are trained to represent vocabulary of the real-world terms that can be combined to form complex knowledge and skill sets. The mentioned NN blocks will be created using neuro-evolutionary algorithms by the method of gradual complexification, creating small and energy-efficient NN topologies that can be executed on a commodity CPUs with minimal power consumption. We call these blocks as &lt;em&gt;Term Artificial Neural Network (&lt;strong&gt;tANN&lt;/strong&gt;)&lt;/em&gt; to emphasize the fact that each NN block represents a specific term in our custom real-world vocabulary.&lt;/p&gt;
&lt;p&gt;In addition, in order to model a more complex behavior, the &lt;em&gt;Supervisor ANN (&lt;strong&gt;sANN&lt;/strong&gt;)&lt;/em&gt; structure will be created to process the output of the tANN units and combine them with a common knowledge of the internal functions of the supervised process or system component.&lt;/p&gt;
&lt;p&gt;It is assumed that Autonomous Artificial Intelligent system will be represented in the form of a complex hierarchy of &lt;em&gt;tANN&lt;/em&gt; and &lt;em&gt;sANN&lt;/em&gt; blocks in combination. Where each block or hierarchy of blocks will be responsible for a particular function, knowledge unit or set of the system skills. Such a modular / hierarchical approach provides a simple means to increase system capacity by introducing additional blocks with specific training. It is also possible to obtain an understanding of the flow of AI system reasoning, following the activations of its constituent blocks. The knowledge transfer also becomes easier by simply taking a NN block trained for a specific vocabulary term and introducing it into the new system.&lt;/p&gt;
&lt;h4 id=&#34;-our-roadmap-for-future-research&#34;&gt;&amp;gt; Our roadmap for future research&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Creating definitions of the basic vocabulary terms&lt;/li&gt;
&lt;li&gt;Creation of configurations of the seed genomes for each specific term of the vocabulary&lt;/li&gt;
&lt;li&gt;Training / breeding of tANN structures from the vocabulary&lt;/li&gt;
&lt;li&gt;Experiments on training / breeding of sANN-structures, capable of solving specific complex problems&lt;/li&gt;
&lt;li&gt;Comparison of the performance of AI agents obtained using the described modular architecture against AI agents trained through traditional methods deep learning methods&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;references&#34;&gt;References:&lt;/h2&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;Joel Lehman and Kenneth O. Stanley, &lt;a href=&#34;http://eplex.cs.ucf.edu/papers/lehman_gptp11.pdf&#34;&gt;Novelty Search and the Problem with Objectives&lt;/a&gt;, Genetic Programming: Theory and Practice IX (GPTP 2011), New York, NY: Springer, 2011&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;Kenneth O. Stanley, &lt;a href=&#34;http://nn.cs.utexas.edu/keyword?stanley:phd04&#34;&gt;Ph.D. Dissertation: EFFICIENT EVOLUTION OF NEURAL NETWORKS THROUGH COMPLEXIFICATION&lt;/a&gt;, Department of Computer Sciences, The University of Texas at Austin, Technical Report~AI-TR-04–39, August 2004&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;Iaroslav Omelianenko, &lt;a href=&#34;https://medium.com/@io42/neuroevolution-evolving-artificial-neural-networks-topology-from-the-scratch-d1ebc5540d84&#34;&gt;Neuroevolution — evolving Artificial Neural Networks topology from the scratch&lt;/a&gt;, Medium, 2018&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;Donald E. Knuth, (1997) The Art of Computer Programming, Volume 1: Fundamental Algorithms Third Edition (Reading, Massachusetts: Addison-Wesley, 1997), xx+650pp. ISBN 0-201-89683-4&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;
&lt;p&gt;Joel Lehman, &lt;a href=&#34;http://joellehman.com/lehman-dissertation.pdf&#34;&gt;Evolution through the search for novelty&lt;/a&gt;, B.S. Ohio State University, 2007&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Creation of Autonomous Artificial Intelligent Agents using Novelty Search method of fitness function optimization</title>
      <link>https://io42.space/publication/rg.2.2.20698.80328/</link>
      <pubDate>Tue, 28 Aug 2018 15:28:14 +0200</pubDate>
      <guid>https://io42.space/publication/rg.2.2.20698.80328/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Self Replication to Preserve Innate Learned Structures in Artificial Neural Networks</title>
      <link>https://io42.space/post/self-replication-to-preserve-innate-learned-structures-in-ann/</link>
      <pubDate>Fri, 27 Jul 2018 18:57:35 +0300</pubDate>
      <guid>https://io42.space/post/self-replication-to-preserve-innate-learned-structures-in-ann/</guid>
      <description>&lt;p&gt;It’s interesting to investigate combination of deep &lt;a href=&#34;https://medium.com/@io42/neuroevolution-evolving-artificial-neural-networks-topology-from-the-scratch-d1ebc5540d84&#34;&gt;neuro-evolution&lt;/a&gt; and self-replication&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; to evolve Artificial Neural Networks (ANNs) able to keep and complexify innate learned structures aimed to fulfill auxiliary tasks (orthogonal to the self-replication).&lt;/p&gt;
&lt;p&gt;In such a way, it may became possible to build &lt;em&gt;evolutionary lineage tree&lt;/em&gt; of ANNs specialized to complete specific tasks under different environmental settings through subsequent training sessions. And the knowledge acquired during all these training sessions will accumulate not only in the form of learned connections’ weights, but in a neural network’s &lt;em&gt;topology&lt;/em&gt; as well.&lt;/p&gt;
&lt;p&gt;Subsequently, with appropriate orchestration of resulting intelligent agents it can be possible to produce swarm intelligence with much higher order of complexity than of each individual agent, able to adequately solve imperfect knowledge problems through weighted consensus among all participants.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Biological life began with the first self-replicator, and natural selection kicked in to favor organisms that are better at replication, resulting in a self- improving mechanism. Analogously, we can construct a self-improving mechanism for artificial intelligence via natural selection, if AI agents had the ability to replicate and improve themselves without additional machinery.&lt;/em&gt;&lt;sup id=&#34;fnref1:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Numerous recent studies have shown that various brain structures include &lt;em&gt;innate knowledge seeds&lt;/em&gt; that explode into inalienable abilities of living organisms to learn or complete specific tasks right from the first seconds of immediate life experience.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Over 90% of our genes are expressed in the development of the brain, and a significant number of those are expressed selectively, in a way that allows the brain to self-assemble, even, to some non-trivial degree in the absence of experience. Mechanisms such as cell division, cell differentiation, cell migration, cell death, and axon guidance combine to self-assemble a rich first draft of the human brain, even prior to experience. Even in the absence of synaptic transmission, the primary mechanism by which experience is conveyed to the brain, the basic structure of the newborn brain is preserved.&lt;/em&gt;&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This demonstrates that different brain structures can be regarded to some extent as a swarm of intelligent agents that effectively combine weighted responses from different regions, from cortex to amygdala, in order to build an adequate complex response on the external stimuli created by the environment. It is also worth noting that different human brain structures was inherited from earlier inhuman forms of life, and we even have brain structures related to prehistoric reptiles. Thus, the development of innate brain structures can be regarded as a long-term evolutionary process of complexification from the most basic structures controlling autonomic peripheral neural system to the most complex structures supporting abstract reasoning. Such kind of increasing complexification allows evolution not to get stuck on local optima and to develop even more complex self-organizing structures through &lt;em&gt;dissipative adaptation&lt;/em&gt;&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Life manages to squeeze exquisite reliability in behaviour on large scales from a jittery herd of individual molecules, without always needing to put each atom in its place, and we might therefore feel encouraged to attempt something similar in our own feats of engineering.&lt;/em&gt;&lt;sup id=&#34;fnref1:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This point of view allows us to consider the evolution of synthetic intelligence in a similar way. The main idea is to simulate the process of natural selection that influences evolution of the life forms, by creating of specific &lt;em&gt;multi-staged environment&lt;/em&gt; that force neuro-evolution to generate highly specialized ANNs that can survive as a swarm. The training multi-stage environment must produce multiple challenges with increasing survival pressure. The key point here is the creation at each stage of an environmental challenge with ever increasing amount of available training signals. This will allow to evolve intelligent systems with innate knowledge of environment from it’s most basic form to a comprehensive understanding of the whole. The search for an evolutionary champion at each training stage can be carried out using a &lt;em&gt;novelty search&lt;/em&gt;&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; method that allows to explore all available survival options and to find the best fit among them.&lt;/p&gt;
&lt;p&gt;By combining orthogonal goals such as self-replication and survival in an increasingly complex environment, it’s possible to create adaptive pressure on the ANN’s evolutionary tree that will ignite the generation of complex systems with innate structures, capable to quickly learn new properties of the environment from the first moments of direct experience. As an added bonus, it will also sustain life-long learning of produced intelligent systems, by effectively incorporating new experiences into innate structures.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Self-replication involves a degree of introspection and self-awareness, which is helpful for lifelong learning and potential discovery of new neural network architectures.&lt;/em&gt;&lt;sup id=&#34;fnref2:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The resulting swarm of intelligent agents can become a foundation for creation of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Artificial_general_intelligence&#34;&gt;Artificial General Intelligence&lt;/a&gt; (AGI) with innate structures that allow to generalize knowledge about new experiences and environmental challenges.&lt;/p&gt;
&lt;p&gt;~&lt;/p&gt;
&lt;p&gt;The repost of the original article posted by author at Medium: &lt;a href=&#34;https://medium.com/@io42/self-replication-to-preserve-innate-leaned-structures-in-artificial-neural-networks-9bd8758662b4&#34;&gt;Self-replication to preserve innate learned structures in Artificial Neural Networks&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;references-1234567&#34;&gt;References: &lt;sup id=&#34;fnref3:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref1:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref2:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref1:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;&lt;/h2&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;Oscar Chang, Hod Lipson, &lt;a href=&#34;https://arxiv.org/abs/1803.05859&#34;&gt;Neural Network Quine&lt;/a&gt;, arXiv preprint: 1803.05859v3, 2018&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref2:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref3:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;Gary Marcus, &lt;a href=&#34;https://arxiv.org/abs/1801.05667&#34;&gt;Innateness, AlphaZero, and Artificial Intelligence&lt;/a&gt;, arXiv preprint: 1801.05667v1, 2018&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;Jeremy L. England, &lt;a href=&#34;https://www.englandlab.com/uploads/7/8/0/3/7803054/nnano.2015.250__1_.pdf&#34;&gt;Dissipative adaptation in driven self-assembly&lt;/a&gt;, Nature Nanotechnology volume 10, pages 919–923, 2015&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref2:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;Joel Lehman, &lt;a href=&#34;http://joellehman.com/lehman-dissertation.pdf&#34;&gt;Evolution through the search for novelty&lt;/a&gt;, B.S. Ohio State University, 2007&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;
&lt;p&gt;Robert Marsland III, Jeremy L. England, &lt;a href=&#34;https://arxiv.org/abs/1711.02172&#34;&gt;Speed, strength and dissipation in biological self-assembly&lt;/a&gt;, arXiv preprint: 1711.02172v1, 2017&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34;&gt;
&lt;p&gt;Sumantra Sarkar, Bin Wang, Jeremy L. England, &lt;a href=&#34;https://arxiv.org/abs/1709.09191&#34;&gt;Design of conditions for emergence of self-replicators&lt;/a&gt;, arXiv preprint: 1709.09191v2, 2018&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34;&gt;
&lt;p&gt;Iaroslav Omelianenko, &lt;a href=&#34;https://medium.com/@io42/neuroevolution-evolving-artificial-neural-networks-topology-from-the-scratch-d1ebc5540d84&#34;&gt;Neuroevolution — evolving Artificial Neural Networks topology from the scratch&lt;/a&gt;, Medium, 2018&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>GO NEAT Novelty Search</title>
      <link>https://io42.space/project/goneat_ns/</link>
      <pubDate>Wed, 25 Jul 2018 18:30:58 +0300</pubDate>
      <guid>https://io42.space/project/goneat_ns/</guid>
      <description></description>
    </item>
    
    <item>
      <title>GO NEAT</title>
      <link>https://io42.space/project/goneat/</link>
      <pubDate>Wed, 25 Jul 2018 17:55:31 +0300</pubDate>
      <guid>https://io42.space/project/goneat/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Neuroevolution</title>
      <link>https://io42.space/post/neuroevolution-evolving-ann-topology-from-the-scratch/</link>
      <pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://io42.space/post/neuroevolution-evolving-ann-topology-from-the-scratch/</guid>
      <description>&lt;p&gt;The most popular method of &lt;a href=&#34;https://en.wikipedia.org/wiki/Artificial_neural_network&#34;&gt;Artificial Neural Networks&lt;/a&gt; (ANN) training - at the time of this essay writing - is to use some form of Gradient Descent (GD) combined with error back propagation w.r.t. objective function defining our learning goal. This methodology was invented about 30 years ago by &lt;a href=&#34;https://en.wikipedia.org/wiki/Geoffrey_Hinton&#34;&gt;Geoffrey Hinton&lt;/a&gt; and become a foundation of all modern research activities in the &lt;a href=&#34;https://en.wikipedia.org/wiki/Deep_learning&#34;&gt;Deep Machine Learning&lt;/a&gt; (ML) and the &lt;a href=&#34;https://en.wikipedia.org/wiki/Artificial_intelligence&#34;&gt;Artificial Intelligence&lt;/a&gt; (AI). But despite the fact that it gives immense power in areas of pattern recognition (&lt;a href=&#34;https://en.wikipedia.org/wiki/Feature_learning&#34;&gt;feature or representation learning&lt;/a&gt;) it has considerable weakness:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the network topology must be fully hand-engineered before training starts and only connection weights encapsulate learned knowledge, the network topology remain the same&lt;/li&gt;
&lt;li&gt;as a result it may introduce oversatturated neural units which don not take part in the training/inference process but simply consuming comptunig resources&lt;/li&gt;
&lt;li&gt;special methodic must be applied to avoid sticking into local optima such as L1/L2-norm, dropout regularizations, etc&lt;/li&gt;
&lt;li&gt;exploding or diminishing learning gradient issues during back/forward propagation&lt;/li&gt;
&lt;li&gt;implemented solutions can generalize only in the narrow scope learned from provided training samples&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;To overcome some of the drawbacks of GD-based training it was proposed to use alternative methods to train/evolve neural networks with group of algorithms inspired by natural selection and genetic evolution. It was given name &lt;a href=&#34;https://en.wikipedia.org/wiki/Genetic_algorithm&#34;&gt;Genetic Algorithms&lt;/a&gt; (GA) to address the source of inspiration and due to its attempt to mimic natural process of genetic mutations, crossover and selection, while trying to solve objective function optimization problem. There are many types of such algorithms was invented during last years.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;crossover_mutation.png&#34; data-caption=&#34;The example of Crossover and Mutation in GA (image source)&#34;&gt;
&lt;img data-src=&#34;crossover_mutation.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    The example of Crossover and Mutation in GA (&lt;a href=&#34;http://www.abrandao.com/2015/01/simple-php-genetic-algorithm/&#34;&gt;image source&lt;/a&gt;)
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;But my main interest in this essay is to present a kind of GA which can be applied to evolve ANNs from the most simple forms to the complex ones in order to find objective function optimization solution not only by changing weights of connections between neural units, but by evolving the topology of network graph itself.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;I would like to consider &lt;a href=&#34;http://www.cs.ucf.edu/~kstanley/neat.html&#34;&gt;Neuroevolution of Augmented Topologies&lt;/a&gt; (NEAT) algorithm invented by &lt;a href=&#34;http://www.cs.ucf.edu/~kstanley/&#34;&gt;Kenneth O. Stanley&lt;/a&gt; as part of his &lt;a href=&#34;http://nn.cs.utexas.edu/keyword?stanley:phd04&#34;&gt;Phd Thesis&lt;/a&gt; in years 2002-2004. With this method of ANN evolution, search for complex solutions made feasible through graduate complexification of network topology. By starting with minimal ANN the NEAT is more likely to find efficient and robust solution, avoiding sticking at the local optima as in cases with other GA methods which starts with elaborated network graphs and mutate them during training.&lt;/p&gt;
&lt;p&gt;With NEAT method, the training starts with very simple ANNs topology comprising of only input, output and bias neural units - no hidden units introduced at the beginning. Thus it ensures, that the system searches for the solution in the lowest-dimensional weight space possible over the course of all generations. The goal is not to minimize only final product, but all intermediate networks along the way as well. This idea is they key to gaining an advantage from the evolution of topology: it allows us to minimize the search space, resulting in dramatic performance gains.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;genotype-phenotype-mapping.png&#34; data-caption=&#34;A genotype to phenotype mapping example. A genotype is depicted that produces the shown phenotype.&#34;&gt;
&lt;img data-src=&#34;genotype-phenotype-mapping.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    A genotype to phenotype mapping example. A genotype is depicted that produces the shown phenotype.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;There are two main types of structural mutations present in the NEAT algorithm: adding the connection between nodes or adding the new node. When mutation is performed, the new added gene (connection gene or node gene) will be assigned with increasingly incremented &lt;em&gt;innovation number&lt;/em&gt;.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;types-of-structural-mutations.png&#34; data-caption=&#34;In adding a connection, a single new connection gene is added to the end of the genome and given the next available innovation number. In adding a new node, the connection gene being split is disabled, and two new connection genes are added to the end the genome. The new node is between the two new connections.&#34;&gt;
&lt;img data-src=&#34;types-of-structural-mutations.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    In adding a connection, a single new connection gene is added to the end of the genome and given the next available innovation number. In adding a new node, the connection gene being split is disabled, and two new connection genes are added to the end the genome. The new node is between the two new connections.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Through mutation, the genomes in NEAT will gradually get larger. Genomes of varying sizes will result, sometimes with different connections (genes) at the same positions.&lt;/p&gt;
&lt;p&gt;There is an unexploited information in evolution, that tells us exactly which genes match up with which genes between &lt;em&gt;any&lt;/em&gt; individuals in a topologically diverse population. That information is the historical origin of each gene. Two genes with the same historical origin must represent the same structure (although possibly with different weights), since they are both derived from the same ancestral gene of some point in the past. Thus, all the system needs to do, in order to know which genes line up with which, is to keep track of the historical origin of every gene in the population’s genome.&lt;/p&gt;
&lt;p&gt;Luckily for us, the &lt;em&gt;innovation numbers&lt;/em&gt; incrementally assigned to the genes during genome mutations is a kind of &lt;em&gt;historical markers&lt;/em&gt; to use for tracking chronology of structural genome mutations. At the same time, during crossover (mating), the offsprings will inherit the same innovation numbers of genes in the parents genome. Thus, innovation number of particular gene will never change, allowing tracking of historical origin of every gene throughout evolution.&lt;/p&gt;
&lt;p&gt;The historical markers give NEAT a power to track which genes match up with which. Thus, during the crossover, system will know exactly how to lineup genes from genomes of both parents. The genes with matching innovation numbers will be called &lt;em&gt;matching&lt;/em&gt; genes. Genes that do not match are either &lt;em&gt;disjoint&lt;/em&gt; or &lt;em&gt;excess&lt;/em&gt;, depending on whether they occur within or outside the range of the other parent’s innovation numbers. They represent structure that is not present in the other parent’s genome. When composing the offspring, genes are randomly chosen from either parent at matching genes, whereas all excess or disjoint genes are always included from the more fit parent. This way, historical markings allow NEAT to perform crossover using linear genomes encoding without the need for expensive topological analysis.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;crossover-using-linear-genomes-encoding.png&#34; data-caption=&#34;During the crossover, the offspring genes are randomly chosen from matching genes of either parent and disjoint/excess genes taken from most fit parent. All diagrams from original NEAT paper, highly recommended reading!&#34;&gt;
&lt;img data-src=&#34;crossover-using-linear-genomes-encoding.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    During the crossover, the offspring genes are randomly chosen from matching genes of either parent and disjoint/excess genes taken from most fit parent. All diagrams from original &lt;a href=&#34;http://nn.cs.utexas.edu/?stanley:gecco02b&#34;&gt;NEAT paper&lt;/a&gt;, highly recommended reading!
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Using proposed method the population of organisms can evolve diverse topologies, but it happens that such population can not evolve and maintain &lt;em&gt;topological innovations&lt;/em&gt; on its own. The smaller structures optimize faster than larger structures. Thus by adding new nodes and connections to some topology we artificially reduce it’s chances for survival. The freshly augmented topologies usually experience initial decrease in the fitness, even though the innovations they represent may be resulting in winning solution in the long run.&lt;/p&gt;
&lt;p&gt;This can be solved by introducing &lt;em&gt;speciation&lt;/em&gt; to the population which additionally limits range of organisms that can mate. With speciation it’s possible to organize crossover in such a way that organisms will compete only in narrow niches instead of all population in general. The idea is to divide the population such that similar topologies are in the same species.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;With all specific tweaks to general GA introduced with NEAT it&amp;rsquo;s possible to build complex ANNs to solve control optimization problems among other unsupervised learning problems. Due to specifics of ANN topology augmentation through complexification and speciation found solutions tends to be performance optimized from the train as well as from the inference point of view. The resulting ANNs topology grows exactly to match problem to be solved without any excess layers of hidden units introduced with traditional approach of ANN&amp;rsquo;s topology hand-engineering.&lt;/p&gt;
&lt;p&gt;Due to this it&amp;rsquo;s possible to build complex ensembles of specific ANNs to solve most complex problems arising when attempting to build AI systems. Such ensembles of highly specialized small ANNs can be combined in a way as neural networks combined in the human brain, where each specific part responsible for the processing of particular stimulus or specialized activity.&lt;/p&gt;
&lt;p&gt;Another application of ANNs ensembles is to create solvers for imperfect information games by applying sub-game solving strategy proposed in this &lt;a href=&#34;https://arxiv.org/abs/1705.02955&#34;&gt;research paper&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;There are exists number of implementations of NEAT algorithm in &lt;a href=&#34;http://eplex.cs.ucf.edu/neat_software/&#34;&gt;diverse programming languages&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The author also provided his own implementation of NEAT in GO programming language with extended verification benchmarks: XOR, single-, and double-pole balancing. The source code of the implementation is available at GitHub: &lt;a href=&#34;https://github.com/yaricom/goNEAT&#34;&gt;https://github.com/yaricom/goNEAT&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The associated research project can be found at ResearchGate: &lt;a href=&#34;https://www.researchgate.net/project/NeuroEvolution-of-Augmented-Topologies&#34;&gt;https://www.researchgate.net/project/NeuroEvolution-of-Augmented-Topologies&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;~&lt;/p&gt;
&lt;p&gt;The repost of the original article posted by author at Medium: &lt;a href=&#34;https://medium.com/@io42/neuroevolution-evolving-artificial-neural-networks-topology-from-the-scratch-d1ebc5540d84&#34;&gt;Neuroevolution - evolving Artificial Neural Networks topology from the scratch&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>FTC 2017 paper presentation</title>
      <link>https://io42.space/talk/ftc2017/</link>
      <pubDate>Wed, 29 Nov 2017 13:30:00 -0800</pubDate>
      <guid>https://io42.space/talk/ftc2017/</guid>
      <description>&lt;p&gt;The full reference of the presented work is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Omelianenko, I (2017). Applying Deep Machine Learning for Psycho-Demographic Profiling of Internet Users using O.C.E.A.N. Model of Personality. Proceedings of the 2017 Future Technologies Conference (SAI) – IEEE, Vancouver, Canada, ISBN (USB) 978-1-5386-1744-1, pp. 375-384&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>FTC 2017, Vancouver, Canada</title>
      <link>https://io42.space/publication/ftc2017/</link>
      <pubDate>Wed, 29 Nov 2017 13:30:00 -0800</pubDate>
      <guid>https://io42.space/publication/ftc2017/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SSVEP Brain Hash Function</title>
      <link>https://io42.space/project/brainhash/</link>
      <pubDate>Thu, 03 Aug 2017 18:25:34 +0300</pubDate>
      <guid>https://io42.space/project/brainhash/</guid>
      <description>&lt;p&gt;This project had a goal to research if steady-state visually evoked potential (SSVEP) can be used to create Brain Hash Function Algorithm able to distinguish between unique footprints of each individual brain under specific visual stimulation with electro-physiological visual feedback based on consumer-grade EEG monitoring device.&lt;/p&gt;
&lt;p&gt;The project scope consist of two major parts:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Implementation of electro-physiological visual feedback system based on consumer-grade EEG monitoring device. It should perform monitoring of EEG signals in real time and perform preprocessing of received raw EEG signal.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Implementation of advance machine-learning pipeline to automatically extract important features from data stream and perform classification of encoded features. It should perform confident classification of the collected EEG data in order to (a) reliably distinguish signal from noise and (b) reliably distinguish between EEG records collected from different human participants.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The project timeline and results can be found at: &lt;a href=&#34;https://www.researchgate.net/project/Brain-Hash-Function&#34;&gt;ResearchGate&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Applying advanced machine learning models to classify electro-physiological activity of human brain for use in biometric identification.</title>
      <link>https://io42.space/publication/arxiv-1708.01167/</link>
      <pubDate>Thu, 03 Aug 2017 17:32:12 +0300</pubDate>
      <guid>https://io42.space/publication/arxiv-1708.01167/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Psistats</title>
      <link>https://io42.space/project/psistats/</link>
      <pubDate>Wed, 05 Jul 2017 19:10:25 +0300</pubDate>
      <guid>https://io42.space/project/psistats/</guid>
      <description>&lt;p&gt;The project had a goal to provide working implementation of psycho-demographic profiling algorithm which can be used to profile Internet users based on digital footprints they leave by using various Internet services. We provide full source code implementation in R programming language of the algorithms described in corresponding research paper.&lt;/p&gt;
&lt;p&gt;We have used variety of machine learning and data mining tools in order to process input data corpus and to create artificial neural networks for multivariate regression analysis.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Applying Deep Machine Learning for psycho-demographic profiling of Internet users using O.C.E.A.N. model of personality.</title>
      <link>https://io42.space/publication/arxiv-1703.06914/</link>
      <pubDate>Tue, 07 Mar 2017 12:27:21 +0300</pubDate>
      <guid>https://io42.space/publication/arxiv-1703.06914/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
