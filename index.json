
        
        
      [{"authors":["admin"],"categories":null,"content":"Iaroslav Omelianenko is a CTO and Research Director at the NewGround LLC. His research interests include human-computer interaction, genetic algorithms, neuroevolution of augmented topologies, reinforcement learning, control \u0026amp; optimization, and Neurobiology.\nHe leads the Research and Development team, which applies genetic algorithms to create artificial neural networks with a minimal footprint to solve a variety of control \u0026amp; optimization tasks as well as do research in brain-computer interfaces.\nHe has more than 30 years of experience with software design, implementation, and project management. He actively participates in open source projects. He presented research papers as an author at international conferences.\nHe is an author of the book Hands-On Neuroevolution with Python now available on Amazon. Also, he co-authored the book Machine Learning and the City: Applications in Architecture and Urban Design.\n","date":1708647300,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1708647300,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://io42.space/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Iaroslav Omelianenko is a CTO and Research Director at the NewGround LLC. His research interests include human-computer interaction, genetic algorithms, neuroevolution of augmented topologies, reinforcement learning, control \u0026amp; optimization, and Neurobiology.\nHe leads the Research and Development team, which applies genetic algorithms to create artificial neural networks with a minimal footprint to solve a variety of control \u0026amp; optimization tasks as well as do research in brain-computer interfaces.\nHe has more than 30 years of experience with software design, implementation, and project management.","tags":null,"title":"Iaroslav Omelianenko","type":"authors"},{"authors":["Iaroslav Omelianenko"],"categories":null,"content":"","date":1708647300,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1708647300,"objectID":"39bcb24bc8ea15f0aa43b18c2f4b0c49","permalink":"https://io42.space/talk/icict2024/","publishdate":"2024-02-22T00:00:00Z","relpermalink":"/talk/icict2024/","section":"talk","summary":"I presented my research paper \\\"Design of cluster-computing architecture to improve training speed of the Neuroevolution algorithm\\\"","tags":["neuroevolution"],"title":"ICICT 2024 paper presentation","type":"talk"},{"authors":["Iaroslav Omelianenko"],"categories":null,"content":"","date":1708618500,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1708618500,"objectID":"dfab2cc88c39dea88443c5490c75b704","permalink":"https://io42.space/publication/icict2024/","publishdate":"2024-02-22T16:15:00Z","relpermalink":"/publication/icict2024/","section":"publication","summary":"In this paper, we review the key features and major draw- backs of the Neuroevolution of Augmenting Topologies (NEAT) algo- rithm, such as slow training speed that limits its area of application. The main reason for the performance issues of the NEAT algorithm is the huge number of calculations required at the end of each epoch to estimate the fitness of each organism in the population. We propose a software system architecture that can be implemented to solve NEAT performance problems based on Ray cluster-computing framework. Fi- nally, we demonstrate how fitness estimation computations can be dis- tributed across stateless distributed workers deployed either on-premise or in the cloud using Ray framework.","tags":["neuroevolution"],"title":"ICICT 2024, London, United Kingdom","type":"publication"},{"authors":["Iaroslav Omelianenko"],"categories":["artificial-neural-networks","neuroevolution"],"content":"","date":1701437294,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701437294,"objectID":"701e3f67cb2934b6c6a4e5b7a61f63be","permalink":"https://io42.space/publication/pp2023.04.076/","publishdate":"2023-12-01T00:00:00Z","relpermalink":"/publication/pp2023.04.076/","section":"publication","summary":"The article deals with the problem of finding a solution for the navigational task of navigating a maze by an autonomous agent controlled by an artificial neural network (ANN). A solution to this problem was proposed by training the controlling ANN using the method of neuroevolution of augmenting topologies (NEAT).","tags":["neuroevolution","unsupervised-learning","reinforcement-learning","cooperative-robotics","evolutionary-computation","novelty-search","autonomous-robotics"],"title":"Simulation of the Autonomous Maze Navigation using the NEAT Algorithm","type":"publication"},{"authors":["Iaroslav Omelianenko"],"categories":["artificial-neural-networks","neuroevolution","evolutionary-computation","smart-city"],"content":"","date":1654097913,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654097913,"objectID":"873a5353ca62a7bee9e414acb95d3aaf","permalink":"https://io42.space/publication/machine-learning-and-the-city/","publishdate":"2022-06-01T17:38:33+02:00","relpermalink":"/publication/machine-learning-and-the-city/","section":"publication","summary":"Machine Learning and the City: Applications in Architecture and Urban Design delivers a robust exploration of machine learning (ML) and artificial intelligence (AI) in the context of the built environment. Relevant contributions from leading scholars in their respective fields describe the ideas and techniques that underpin ML and AI, how to begin using ML and AI in urban design, and the likely impact of ML and AI on the future of city design and planning.","tags":["neuroevolution","evolutionary-computation","smart-city","reinforcement-learning","unsupervised-learning"],"title":"Machine Learning and the City: Applications in Architecture and Urban Design","type":"publication"},{"authors":["Iaroslav Omelianenko"],"categories":["artificial-neural-networks","neuroevolution","evolutionary-computation","autonomous-robotics"],"content":"","date":1577893113,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577893113,"objectID":"71a776e04df0318c6f59b71031d93951","permalink":"https://io42.space/publication/hands-on-neuroevolution-with-python/","publishdate":"2020-01-01T17:38:33+02:00","relpermalink":"/publication/hands-on-neuroevolution-with-python/","section":"publication","summary":"Neuroevolution is a form of artificial intelligence learning that uses evolutionary algorithms to simplify the process of solving complex tasks in domains such as games, robotics, and the simulation of natural processes. This book will give you comprehensive insights into essential neuroevolution concepts and equip you with the skills you need to apply neuroevolution-based algorithms to solve practical, real-world problems.","tags":["neuroevolution","novelty-search","evolutionary-computation","autonomous-robotics","reinforcement-learning","unsupervised-learning"],"title":"Hands-On Neuroevolution With Python","type":"publication"},{"authors":["Iaroslav Omelianenko"],"categories":["artificial-neural-networks","neuroevolution","autonomous-robotics"],"content":"","date":1549371937,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549371937,"objectID":"313afaca6083d935a9113fe1d74140d6","permalink":"https://io42.space/publication/preprints201901.0282/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprints201901.0282/","section":"publication","summary":"In this paper, we look at how Artificial Swarm Intelligence can evolve using evolutionary algorithms that try to minimize the sensory surprise of the system. We will show how to apply the free-energy principle, borrowed from statistical physics, to quantitatively describe the optimization method (sensory surprise minimization), which can be used to support lifelong learning.","tags":["neuroevolution","free-energy-principle","swarm-intelligence","cooperative-robotics","evolutionary-computation","novelty-search","autonomous-robotics"],"title":"Artificial Swarm Intelligence and Cooperative Robotic Systems","type":"publication"},{"authors":["Iaroslav Omelianenko"],"categories":["artificial-neural-networks","neuroevolution"],"content":"For billions of years of evolution, biological intelligent agents have mastered the power to find optimal solutions in deceptive environments that we encounter in our daily interactions with the real world. We can easy navigate themselves through the maze of a big city subways and roadways. But for artificial intelligent systems, this is too difficult to be easily solved using the optimal computing resources. This is especially true for offline autonomous agents that are not backed by super power of cloud servers.\nThe main problem here is related to the fact that reliable maze navigation requires the development of a solution in an environment having many traps with strong local optima of fitness function. Such traps are represented as cul-de-sacs that are close to the final destination, but that can not be escaped without a step back, away from the ultimate goal (at least temporary). In such environments, objective-based solvers basically can not find optimal solution or any solution at all, because they do not have the necessary internal machinery for committing the leap-of-faith and move backward from the target in order to eventually find a way out.\nThe objective-based solvers depends on the best attempts of their designers to assess the operating environment and develop a better way to achieve the ultimate goal. But, as it happens in the real world, preliminary assumptions often can not account for all the traps on the way to the goal because of the extreme complexity of the environment settings. And even in simple artificial environments, such as maze navigation, it often happens that objective-based solvers can not find the optimal solution within the adequate execution time and computational resources allocation. But for successful autonomous execution in real world environments, it is critically important to create Intelligent Agents capable of quickly finding a solution with minimal computational load.\nEXPERIMENT OVERVIEW In the experiment we studied how Novelty Search (NS)1 method of fitness function optimization performs compared to traditional objective-based ones for unsupervised training of Artificial Intelligent Agents to do spatial navigation in complex maze environment. The main idea behind NS optimization is to rather look for novel outcomes in the search space than the distance to the final objective: the maze exit. The Novelty Search assigns higher fitness values to the Intelligent Agent capable to find the most novel solution among all previous tries. Despite its ignorance to the final objective the NS happens to be extremely effective optimization method capable of breeding AAIA, which crack deceptive real-world tasks even in the realms where traditional objective-based methods have failed completely. The main assumption about what makes this possible, is that in order to reach final goal, AAIA must find several intermediate goals (stepping stones) which in most cases do not resemble the ultimate objective. Sometimes Intelligent Agent must step back to avoid deceptive traps. By doing this it will see a decrease in value of objective-based fitness function for a moment but will get a better outcomes in the future. This is one of the fundamental properties of the real-world environment that the exact route to the final objective in most cases can not be predicted in advance, and all intermediate stepping stones should be found by taking the path.\nThe Novelty Search optimization seems like a natural fit for Neuro-evolution family of genetic algorithms producing elegant custom Artificial Neural Networks (ANNs). In the experiment we combined NS with Neuroevolution of Augmented Topologies algorithm2 which efficiently evolve ANNs through complexification by augmenting its topologies.\nMore details about NEAT algorithm implementation can be found in my previous article: ‘Neuroevolution — evolving Artificial Neural Networks topology from the scratch’3\n\u0026gt; The Maze Solver Agent Configuration Autonomous Artificial Intelligent Agent, designed to solve the maze, has ten input sensors that allow collecting information about the environment and two output effectors controlling its movements through the maze (see Figure 1). The final objective of the agent is to go through the maze and find a way out.\nThe configuration schema of the maze agent with input sensors plot The input sensors are: six range finders that indicate the distance to the nearest obstacle (blue arrows) and four pie-slice radar sensors (slices of red circle) that act as a compass towards the goal (maze exit), activating when a line from the goal to the center of the agent falls within the pie-slice. The green-yellow arrow in the center points to the movement direction of the agent.\nThe agent is also equipped with two effectors producing a forces that respectively turn and propel the robot, i.e. change its linear and angular velocity.\n\u0026gt; Seed Genome Configuration The configuration of the seed genome of the solver agent can be summarized as follows (see Figure 2):\nten input (sensor) neurons (blue): six for range finders [RIGHT, FRONT-RIGHT, FRONT, FRONT-LEFT, LEFT, BACK] plus four for slice radar sensors with 45 degree FOV [FRONT, LEFT, BACK, RIGHT] two output (effectors) neurons (red): angular (neuron #13) and linear (neuron #14) velocity controlling effectors one hidden neuron (#12) to introduce non linearity (green) one bias neuron (#1) to avoid zero saturation when input neurons is not activated (yellow) The seed genome configuration The input neurons has following numbers on the diagram above:\nRange Finders: #2 — RIGHT, #3 — FRONT-RIGHT, #4 — FRONT, #5 — FRONT-LEFT, #6 — LEFT, #7 — BACK Radar Sensors: #8 — FRONT, #9 — LEFT, #10 — BACK, #11 — RIGHT \u0026gt; The Novelty Search metric definition for a maze environment The Novelty Search optimization method is based on novelty metric calculation for each solver agent after performing a certain number of time steps in simulation of maze navigation for that agent. The novelty metric biases the search in a fundamentally different way than the objective-based fitness function (which depends only on the distance from the agent to the exit) and determines the behavior-space through which the search will be performed. Therefore, since what is important in the maze, this is where the solving agent ends navigation, then for the maze domain, the behavior of a navigator is defined as its final position. The novelty metric then maximizes the N-nearest neighbor distance4 between the final positions of all known solving agents, i.e. the most distant agent will have the greatest score of the novelty metric.\nThe effect of this novelty metric is to reward the solver agent for ending in a place where none have ended before and the method of traversal is ignored. This measure reflects that what is important, is to reach a certain location (i.e. the goal) rather than the method of locomotion. Thus, although the novelty metric has no knowledge of the ultimate goal, a solution that reaches the goal can appear novel. In addition, the comparison between fitness-based and novelty-based search is fair because both scores are calculated only based on the distance of the final position of the agent from other points.\nEXPERIMENT RESULTS As for deceptive environments we choose two types of maze environments with different complexity as was recommended in this research5: medium and hard maze. The maze configurations was designed in such a way as to create many cul-de-sacs with strong local optima, deceiving the objective-based optimization methods.\nThe Medium Complexity Maze Environment The first experiment to establish baseline performance metric was performed using maze configuration of medium complexity. The Novelty Search optimization was combined with Neuro-Evolution of Augmented Topologies algorithm which use genetic neuro-evolution process to create a population of organisms capable of solving a maze. We also compared its performance with the objective-based optimization method for the NEAT algorithm, where fitness function optimization was dependent on how close final destination of produced organism is from the exit of the maze.\nThe final performance metric of each Autonomous Agent created for both optimization methods depends only on how close to the maze exit is the final destination of the solver after $400$ stimulation steps. Thus, despite the various methods of fitness function optimization, the final results can be compared for both methods. Each experimental trial was performed with $2000$ epochs of evolution or until a winner is found.\n\u0026gt; Novelty Search Optimization Applying Novelty Search based optimization it was possible to get the winner in 10 form 10 trials with optimal genome found approximately within $50$ generations. An Artificial Neural Network produced by an organism with a near optimal genome has $1$ neurons with only three hidden units, i.e. it was capable of growing two additional units compared to the above-mentioned seed genome (see Figure 2). And it is able to control maze solver agent with a spatial error of about $1.9%$ for targeting the exit of the maze.\nThe medium maze winner\u0026rsquo;s genome when Novelty Search optimization method applied Among with the two additional hidden units (neurons), the recurrent link was developed at the output neuron #13 (angular velocity effector) — see Figure 3. The recurrent link at this output neuron appears to be of great importance, since it was introduced in each configuration of the winner’s genome generated in each test trial. Such a consistent pattern seems pretty reasonable for the neuron #13, because it affects the agent’s steering and requires learning more complicated behavior compared to the neuron #14 (linear velocity control).\nIt is also interesting to consider the hidden neuron #91, which seemingly have learned the complex behavior of the steering to the exit of the maze when it is discovered to the right or behind the agent. We\u0026rsquo;ve made such assumptions because of its connections with input sensors #2, #7 (range finders: RIGHT, BACK) and #10, #11 (radar sensors: BACK, RIGHT).\nThe hidden neuron #293 connected with input sensor #11 (radar sensor: RIGHT), has learned to influence the steering of the agent in the direction of the exit of the maze, since most of the time the exit is on the right bottom relative to the agent.\nThe hidden neuron #12 which is introduced in seed genome operates as main control-and-relay switch relaying signals from sensors and other hidden neurons to the effectors (neurons #13, #14).\nThe color coded final positions of NS maze solvers for medium maze environment On the Figure 4 presented a diagram of the maze solving simulation by solver agents controlled by ANNs, derived from the genomes of all organisms introduced into the population until a winner is found. Agents are coded by color depending on which species the source organism belongs to. The fitness of agent is measured as the relative distance between its final destination and maze exit after running simulation for certain number of time steps ($400$ in our setup).\nThe initial agent position is at the top-left corner marked with green circle and maze exit at the bottom-right marked with red circle.\nThe upper plot shows the final destinations of the most fit agents ($fitness \u0026gt;= 0.8$), and the lower plot - the rest. The results are presented for an experimental trial producing the configuration of the winner genome depicted at Figure 3. The total number of species created at that trial is $32$, with only $8$ becoming the most fit ones ($fitness \u0026gt;= 0.8$).\n\u0026gt; Objective-Based Optimization Applying objective-based optimization, it was possible to create the winners capable of solving medium maze configuration in 9 from 10 trials. But the configuration of the winner\u0026rsquo;s genome in most cases was not so elegant and energy efficient, as with above-mentioned Novelty Search optimization.\nThe medium maze winner\u0026rsquo;s genome when objective-based fitness function optimization method applied After $248$ generations, it was found near optimal configuration of the winner\u0026rsquo;s genome (see Figure 5), capable of guiding the maze solving agent through the medium-complexity maze and reach the exit of the maze with spatial error about $1.8%$. The artificial neural network produced by this genome has $22$ units (neurons) with nine hidden neurons for modeling complex learned behavior.\nThe color coded final positions of objective-based maze solvers for medium maze environment Comparing the objective-based simulation plot (Figure 6) with the similar for simulation based on Novelty Search optimization, it can be seen that agents final destinations are distributed less evenly through the maze space. Another interesting point is that most fit agents were less exploratory, moving mainly along the maze walls towards the local fitness optima. This behavior resulted in more generations needed to produce the winner on average, as well as completely failed trials.\nThe Hard Complexity Maze Environment The hard maze configuration introduces additional complexity, emphasizing the idiosyncrasies of the objective-based optimization method. This requires a bit of strategic thinking, which sometimes allows the agent to deviate from the seemingly optimal places (with high local fitness function values) to finally find the guiding path through the maze. The ability of Novelty Search optimization to mimic mentioned strategic reasoning due to its inherent ability to find all the promising areas of the search space has made it an absolute champion with this experiment.\n\u0026gt; Novelty Search Optimization The Novelty Search optimization method, produced solving agents capable to solve the hard maze in 10 from 10 trials. The power of NS method led to the finding of winning solvers within up to $100$ generations in the maze environment of both: medium and hard complexity. Which marks NS as a highly effective optimization method for creating Autonomous Artificial Intelligent Agents capable of complex spatial navigation.\nThe hard maze winner\u0026rsquo;s genome when Novelty Search optimization method applied After $109$ generations of populations of organisms, the near optimal configuration of the winner\u0026rsquo;s genome was found (see Figure 7). The winner is able to guide the agent through the hard maze environment and approach the exit with a spatial error $2.5%$. The Artificial Neural Network produced by this genome has only $17$ units (neurons) with four hidden neurons for modeling complex learned behavior.\nIt is interesting to note that recurrent link on the output neuron #13 (angular velocity effector) was routed through two hidden neurons compared with the medium maze, where the neuron #13 was simply linked to itself. This may result in more complex behavior learned, especially taking into account that link passes through the neuron #42, affected by the range finder: LEFT and the radar: BACK. The neuron #42 is also affected by connection to the neuron #643 (affected by the range finder: LEFT). As a result, we can assume that it learned how to steer the agent when the exit of the maze is behind, and the wall is on the left, i.e. follow the left wall, moving forward.\nAnother important point to consider is about possible learned behavior encoded in the hidden neuron #297, which is affected by input range finder sensors detecting distance to obstacles in the RIGHT and FRONT direction. Considering the maze configuration, we can assume that this neuron learned to avoid the left chamber\u0026rsquo;s trap, where an extremely strong local maximum of the fitness function was introduced (based on the distance to the exit of the maze).\nThe color coded final positions of NS maze solvers for hard maze environment Because of the inherent complexity of the hard maze environment, only one species from $35$ was able to beget genome with fitness greater than $0.8$. This genome is also the winner able to produce control ANN successfully guiding solver agent to the exit of the maze. But, as can be seen from the Figure 8, there is a high probability that as the number of simulation steps increases, a larger number of species will be able to hit the fitness threshold ($0.8$).\n\u0026gt; Objective-Based Optimization The objective-based fitness function optimization method completely failed to create any successful solver agent within all 10 experiment trials. In some trials, it was able to create AAIAs, almost finding the exit of the maze, but it seems that many more simulation steps are required to eventually produce the winner genome, which makes it too computationally expensive.\nThe color coded final positions of NS maze solvers for hard maze environment The Figure 9 depicts the most successful trials of the hard maze solvers with objective-based optimization of the fitness function. Looking at it, it can be seen that most of the final destinations of the Intelligent Agents were trapped in deceptive cul-de-sacs, blocking them from further exploration of the maze environment search space.\nDISCUSSION As shown by our experimental data, the Novelty Search method of fitness function optimization, when the fitness of the agent is based on the novelty of the solution that it was able to find, significantly outperforms traditional objective-based optimization and was even able to solve the navigation task when the traditional method failed completely.\nWe believe that Novelty Search optimization can be successfully applied to create optimal solving agents in many areas where strong deceptive local optima of fitness function prevents traditional objective-based methods from finding optimal or any solutions at all.\nThe full source code of the experiment implemented in GoLang: https://github.com/yaricom/goNEAT_NS. Please refer to it for more details about experiment particulars.\nThe associated research project can be found at ResearchGate: https://www.researchgate.net/project/Novelty-Search-optimization-for-NeuroEvolution\nThe author\u0026rsquo;s NEAT algorithm implementation in the GO language is also shared through NEAT software catalog, hosted by Evolutionary Complexity (EPlex) Research Group at the University of Central Florida: http://eplex.cs.ucf.edu/neat_software/\nSpecial thanks to Dr. Kenneth O. Stanley for advises and sharing the NEAT algorithm details.\nFUTURE WORK We consider the development of modular AI systems based on ensembles of highly optimized compact Neural Networks. Our goal is to create compact utility NN blocks that are trained to represent vocabulary of the real-world terms that can be combined to form complex knowledge and skill sets. The mentioned NN blocks will be created using neuro-evolutionary algorithms by the method of gradual complexification, creating small and energy-efficient NN topologies that can be executed on a commodity CPUs with minimal power consumption. We call these blocks as Term Artificial Neural Network (tANN) to emphasize the fact that each NN block represents a specific term in our custom real-world vocabulary.\nIn addition, in order to model a more complex behavior, the Supervisor ANN (sANN) structure will be created to process the output of the tANN units and combine them with a common knowledge of the internal functions of the supervised process or system component.\nIt is assumed that Autonomous Artificial Intelligent system will be represented in the form of a complex hierarchy of tANN and sANN blocks in combination. Where each block or hierarchy of blocks will be responsible for a particular function, knowledge unit or set of the system skills. Such a modular / hierarchical approach provides a simple means to increase system capacity by introducing additional blocks with specific training. It is also possible to obtain an understanding of the flow of AI system reasoning, following the activations of its constituent blocks. The knowledge transfer also becomes easier by simply taking a NN block trained for a specific vocabulary term and introducing it into the new system.\n\u0026gt; Our roadmap for future research Creating definitions of the basic vocabulary terms Creation of configurations of the seed genomes for each specific term of the vocabulary Training / breeding of tANN structures from the vocabulary Experiments on training / breeding of sANN-structures, capable of solving specific complex problems Comparison of the performance of AI agents obtained using the described modular architecture against AI agents trained through traditional methods deep learning methods References: Joel Lehman and Kenneth O. Stanley, Novelty Search and the Problem with Objectives, Genetic Programming: Theory and Practice IX (GPTP 2011), New York, NY: Springer, 2011\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKenneth O. Stanley, Ph.D. Dissertation: EFFICIENT EVOLUTION OF NEURAL NETWORKS THROUGH COMPLEXIFICATION, Department of Computer Sciences, The University of Texas at Austin, Technical Report~AI-TR-04–39, August 2004\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIaroslav Omelianenko, Neuroevolution — evolving Artificial Neural Networks topology from the scratch, Medium, 2018\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDonald E. Knuth, (1997) The Art of Computer Programming, Volume 1: Fundamental Algorithms Third Edition (Reading, Massachusetts: Addison-Wesley, 1997), xx+650pp. ISBN 0-201-89683-4\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJoel Lehman, Evolution through the search for novelty, B.S. Ohio State University, 2007\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":1536192000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536192000,"objectID":"0cbf31fb87c02f0c9c932ce40d074382","permalink":"https://io42.space/post/creation-aaia-using-novelty-search/","publishdate":"2018-09-06T00:00:00Z","relpermalink":"/post/creation-aaia-using-novelty-search/","section":"post","summary":"The Novelty Search optimization seems like a natural fit for Neuro-evolution family of genetic algorithms producing elegant custom Artificial Neural Networks (ANNs). In the experiment we combined NS with Neuroevolution of Augmented Topologies algorithm which efficiently evolve ANNs through complexification by augmenting its topologies.","tags":["neuroevolution","novelty-search","reinforcement-learning","unsupervised-learning"],"title":"Creation of Autonomous Artificial Intelligent Agents using Novelty Search method of fitness function optimization","type":"post"},{"authors":["Iaroslav Omelianenko"],"categories":["artificial-neural-networks","neuroevolution"],"content":"","date":1535462894,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535462894,"objectID":"7c3a8c10474c473658f94d457b04d333","permalink":"https://io42.space/publication/rg.2.2.20698.80328/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/rg.2.2.20698.80328/","section":"publication","summary":"In this work we describe experiment of applying Novelty Search method of fitness function optimization combined with Neuro-Evolution of Augmenting Topologies (NEAT) algorithm to produce Autonomous Artificial Intelligent Agents capable to solve spatial navigation task in complex maze environment.","tags":["neuroevolution","unsupervised-learning","reinforcement-learning","cooperative-robotics","evolutionary-computation","novelty-search","autonomous-robotics"],"title":"Creation of Autonomous Artificial Intelligent Agents using Novelty Search method of fitness function optimization","type":"publication"},{"authors":["Iaroslav Omelianenko"],"categories":["artificial-neural-networks","artificial-general-intelligence"],"content":"It’s interesting to investigate combination of deep neuro-evolution and self-replication1 to evolve Artificial Neural Networks (ANNs) able to keep and complexify innate learned structures aimed to fulfill auxiliary tasks (orthogonal to the self-replication).\nIn such a way, it may became possible to build evolutionary lineage tree of ANNs specialized to complete specific tasks under different environmental settings through subsequent training sessions. And the knowledge acquired during all these training sessions will accumulate not only in the form of learned connections’ weights, but in a neural network’s topology as well.\nSubsequently, with appropriate orchestration of resulting intelligent agents it can be possible to produce swarm intelligence with much higher order of complexity than of each individual agent, able to adequately solve imperfect knowledge problems through weighted consensus among all participants.\nBiological life began with the first self-replicator, and natural selection kicked in to favor organisms that are better at replication, resulting in a self- improving mechanism. Analogously, we can construct a self-improving mechanism for artificial intelligence via natural selection, if AI agents had the ability to replicate and improve themselves without additional machinery.1\nNumerous recent studies have shown that various brain structures include innate knowledge seeds that explode into inalienable abilities of living organisms to learn or complete specific tasks right from the first seconds of immediate life experience.\nOver 90% of our genes are expressed in the development of the brain, and a significant number of those are expressed selectively, in a way that allows the brain to self-assemble, even, to some non-trivial degree in the absence of experience. Mechanisms such as cell division, cell differentiation, cell migration, cell death, and axon guidance combine to self-assemble a rich first draft of the human brain, even prior to experience. Even in the absence of synaptic transmission, the primary mechanism by which experience is conveyed to the brain, the basic structure of the newborn brain is preserved.2\nThis demonstrates that different brain structures can be regarded to some extent as a swarm of intelligent agents that effectively combine weighted responses from different regions, from cortex to amygdala, in order to build an adequate complex response on the external stimuli created by the environment. It is also worth noting that different human brain structures was inherited from earlier inhuman forms of life, and we even have brain structures related to prehistoric reptiles. Thus, the development of innate brain structures can be regarded as a long-term evolutionary process of complexification from the most basic structures controlling autonomic peripheral neural system to the most complex structures supporting abstract reasoning. Such kind of increasing complexification allows evolution not to get stuck on local optima and to develop even more complex self-organizing structures through dissipative adaptation3.\nLife manages to squeeze exquisite reliability in behaviour on large scales from a jittery herd of individual molecules, without always needing to put each atom in its place, and we might therefore feel encouraged to attempt something similar in our own feats of engineering.3\nThis point of view allows us to consider the evolution of synthetic intelligence in a similar way. The main idea is to simulate the process of natural selection that influences evolution of the life forms, by creating of specific multi-staged environment that force neuro-evolution to generate highly specialized ANNs that can survive as a swarm. The training multi-stage environment must produce multiple challenges with increasing survival pressure. The key point here is the creation at each stage of an environmental challenge with ever increasing amount of available training signals. This will allow to evolve intelligent systems with innate knowledge of environment from it’s most basic form to a comprehensive understanding of the whole. The search for an evolutionary champion at each training stage can be carried out using a novelty search4 method that allows to explore all available survival options and to find the best fit among them.\nBy combining orthogonal goals such as self-replication and survival in an increasingly complex environment, it’s possible to create adaptive pressure on the ANN’s evolutionary tree that will ignite the generation of complex systems with innate structures, capable to quickly learn new properties of the environment from the first moments of direct experience. As an added bonus, it will also sustain life-long learning of produced intelligent systems, by effectively incorporating new experiences into innate structures.\nSelf-replication involves a degree of introspection and self-awareness, which is helpful for lifelong learning and potential discovery of new neural network architectures.1\nThe resulting swarm of intelligent agents can become a foundation for creation of the Artificial General Intelligence (AGI) with innate structures that allow to generalize knowledge about new experiences and environmental challenges.\n~\nThe repost of the original article posted by author at Medium: Self-replication to preserve innate learned structures in Artificial Neural Networks\nReferences: 1234567 Oscar Chang, Hod Lipson, Neural Network Quine, arXiv preprint: 1803.05859v3, 2018\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGary Marcus, Innateness, AlphaZero, and Artificial Intelligence, arXiv preprint: 1801.05667v1, 2018\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJeremy L. England, Dissipative adaptation in driven self-assembly, Nature Nanotechnology volume 10, pages 919–923, 2015\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJoel Lehman, Evolution through the search for novelty, B.S. Ohio State University, 2007\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRobert Marsland III, Jeremy L. England, Speed, strength and dissipation in biological self-assembly, arXiv preprint: 1711.02172v1, 2017\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSumantra Sarkar, Bin Wang, Jeremy L. England, Design of conditions for emergence of self-replicators, arXiv preprint: 1709.09191v2, 2018\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIaroslav Omelianenko, Neuroevolution — evolving Artificial Neural Networks topology from the scratch, Medium, 2018\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":1532707055,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532707055,"objectID":"8dd44f12ed29b1adab93202b30bf2403","permalink":"https://io42.space/post/self-replication-to-preserve-innate-learned-structures-in-ann/","publishdate":"2018-07-27T18:57:35+03:00","relpermalink":"/post/self-replication-to-preserve-innate-learned-structures-in-ann/","section":"post","summary":"It’s interesting to investigate combination of deep neuro-evolution and self-replication to evolve Artificial Neural Networks (ANNs) able to keep and complexify innate learned structures aimed to fulfill auxiliary tasks (orthogonal to the self-replication).","tags":["neuroevolution","artificial-neural-networks","novelty-search","self-replication"],"title":"Self Replication to Preserve Innate Learned Structures in Artificial Neural Networks","type":"post"},{"authors":null,"categories":null,"content":"","date":1532532658,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532532658,"objectID":"95399408f4e410406fd87c269f42e73d","permalink":"https://io42.space/project/goneat_ns/","publishdate":"2018-07-25T18:30:58+03:00","relpermalink":"/project/goneat_ns/","section":"project","summary":"This project provides GOLang implementation of Neuro-Evolution of Augmented Topologies (NEAT) algorithm which uses Novelty Search optimization to find a solution for deceptive tasks with strong local optima.","tags":["reinforcement-learning","unsupervised-learning","neuroevolution","novelty-search"],"title":"GO NEAT Novelty Search","type":"project"},{"authors":null,"categories":null,"content":"","date":1532530531,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532530531,"objectID":"70e233de92aeb845bdd8a6f619fecc0d","permalink":"https://io42.space/project/goneat/","publishdate":"2018-07-25T17:55:31+03:00","relpermalink":"/project/goneat/","section":"project","summary":"This project provides GOLang implementation of Neuro-Evolution of Augmented Topologies (NEAT) algorithm. The neuroevolution methods of ANN training allows us to start with a very simple synthetic organism and evolve it to produce a unit of intelligence that represents an approximation of a complex real-world concept. The training accomplished by gradual complexification of the topology of neural networks that are encoded into the genome of a synthetic intelligence unit.","tags":["reinforcement-learning","unsupervised-learning","neuroevolution"],"title":"GO NEAT","type":"project"},{"authors":["Iaroslav Omelianenko"],"categories":["artificial-neural-networks","neuroevolution"],"content":"The most popular method of Artificial Neural Networks (ANN) training - at the time of this essay writing - is to use some form of Gradient Descent (GD) combined with error back propagation w.r.t. objective function defining our learning goal. This methodology was invented about 30 years ago by Geoffrey Hinton and become a foundation of all modern research activities in the Deep Machine Learning (ML) and the Artificial Intelligence (AI). But despite the fact that it gives immense power in areas of pattern recognition (feature or representation learning) it has considerable weakness:\nthe network topology must be fully hand-engineered before training starts and only connection weights encapsulate learned knowledge, the network topology remain the same as a result it may introduce oversatturated neural units which don not take part in the training/inference process but simply consuming comptunig resources special methodic must be applied to avoid sticking into local optima such as L1/L2-norm, dropout regularizations, etc exploding or diminishing learning gradient issues during back/forward propagation implemented solutions can generalize only in the narrow scope learned from provided training samples To overcome some of the drawbacks of GD-based training it was proposed to use alternative methods to train/evolve neural networks with group of algorithms inspired by natural selection and genetic evolution. It was given name Genetic Algorithms (GA) to address the source of inspiration and due to its attempt to mimic natural process of genetic mutations, crossover and selection, while trying to solve objective function optimization problem. There are many types of such algorithms was invented during last years.\nThe example of Crossover and Mutation in GA (image source) But my main interest in this essay is to present a kind of GA which can be applied to evolve ANNs from the most simple forms to the complex ones in order to find objective function optimization solution not only by changing weights of connections between neural units, but by evolving the topology of network graph itself.\nI would like to consider Neuroevolution of Augmented Topologies (NEAT) algorithm invented by Kenneth O. Stanley as part of his Phd Thesis in years 2002-2004. With this method of ANN evolution, search for complex solutions made feasible through graduate complexification of network topology. By starting with minimal ANN the NEAT is more likely to find efficient and robust solution, avoiding sticking at the local optima as in cases with other GA methods which starts with elaborated network graphs and mutate them during training.\nWith NEAT method, the training starts with very simple ANNs topology comprising of only input, output and bias neural units - no hidden units introduced at the beginning. Thus it ensures, that the system searches for the solution in the lowest-dimensional weight space possible over the course of all generations. The goal is not to minimize only final product, but all intermediate networks along the way as well. This idea is they key to gaining an advantage from the evolution of topology: it allows us to minimize the search space, resulting in dramatic performance gains.\nA genotype to phenotype mapping example. A genotype is depicted that produces the shown phenotype. There are two main types of structural mutations present in the NEAT algorithm: adding the connection between nodes or adding the new node. When mutation is performed, the new added gene (connection gene or node gene) will be assigned with increasingly incremented innovation number.\nIn adding a connection, a single new connection gene is added to the end of the genome and given the next available innovation number. In adding a new node, the connection gene being split is disabled, and two new connection genes are added to the end the genome. The new node is between the two new connections. Through mutation, the genomes in NEAT will gradually get larger. Genomes of varying sizes will result, sometimes with different connections (genes) at the same positions.\nThere is an unexploited information in evolution, that tells us exactly which genes match up with which genes between any individuals in a topologically diverse population. That information is the historical origin of each gene. Two genes with the same historical origin must represent the same structure (although possibly with different weights), since they are both derived from the same ancestral gene of some point in the past. Thus, all the system needs to do, in order to know which genes line up with which, is to keep track of the historical origin of every gene in the population’s genome.\nLuckily for us, the innovation numbers incrementally assigned to the genes during genome mutations is a kind of historical markers to use for tracking chronology of structural genome mutations. At the same time, during crossover (mating), the offsprings will inherit the same innovation numbers of genes in the parents genome. Thus, innovation number of particular gene will never change, allowing tracking of historical origin of every gene throughout evolution.\nThe historical markers give NEAT a power to track which genes match up with which. Thus, during the crossover, system will know exactly how to lineup genes from genomes of both parents. The genes with matching innovation numbers will be called matching genes. Genes that do not match are either disjoint or excess, depending on whether they occur within or outside the range of the other parent’s innovation numbers. They represent structure that is not present in the other parent’s genome. When composing the offspring, genes are randomly chosen from either parent at matching genes, whereas all excess or disjoint genes are always included from the more fit parent. This way, historical markings allow NEAT to perform crossover using linear genomes encoding without the need for expensive topological analysis.\nDuring the crossover, the offspring genes are randomly chosen from matching genes of either parent and disjoint/excess genes taken from most fit parent. All diagrams from original NEAT paper, highly recommended reading! Using proposed method the population of organisms can evolve diverse topologies, but it happens that such population can not evolve and maintain topological innovations on its own. The smaller structures optimize faster than larger structures. Thus by adding new nodes and connections to some topology we artificially reduce it’s chances for survival. The freshly augmented topologies usually experience initial decrease in the fitness, even though the innovations they represent may be resulting in winning solution in the long run.\nThis can be solved by introducing speciation to the population which additionally limits range of organisms that can mate. With speciation it’s possible to organize crossover in such a way that organisms will compete only in narrow niches instead of all population in general. The idea is to divide the population such that similar topologies are in the same species.\nWith all specific tweaks to general GA introduced with NEAT it\u0026rsquo;s possible to build complex ANNs to solve control optimization problems among other unsupervised learning problems. Due to specifics of ANN topology augmentation through complexification and speciation found solutions tends to be performance optimized from the train as well as from the inference point of view. The resulting ANNs topology grows exactly to match problem to be solved without any excess layers of hidden units introduced with traditional approach of ANN\u0026rsquo;s topology hand-engineering.\nDue to this it\u0026rsquo;s possible to build complex ensembles of specific ANNs to solve most complex problems arising when attempting to build AI systems. Such ensembles of highly specialized small ANNs can be combined in a way as neural networks combined in the human brain, where each specific part responsible for the processing of particular stimulus or specialized activity.\nAnother application of ANNs ensembles is to create solvers for imperfect information games by applying sub-game solving strategy proposed in this research paper.\nThere are exists number of implementations of NEAT algorithm in diverse programming languages.\nThe author also provided his own implementation of NEAT in GO programming language with extended verification benchmarks: XOR, single-, and double-pole balancing. The source code of the implementation is available at GitHub: https://github.com/yaricom/goNEAT\nThe associated research project can be found at ResearchGate: https://www.researchgate.net/project/NeuroEvolution-of-Augmented-Topologies\n~\nThe repost of the original article posted by author at Medium: Neuroevolution - evolving Artificial Neural Networks topology from the scratch\n","date":1532476800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532476800,"objectID":"226391ad96b2e17b9fa955befe632e06","permalink":"https://io42.space/post/neuroevolution-evolving-ann-topology-from-the-scratch/","publishdate":"2018-07-25T00:00:00Z","relpermalink":"/post/neuroevolution-evolving-ann-topology-from-the-scratch/","section":"post","summary":"The neuroevolution methods of ANN training allows us to start with a very simple synthetic organism and evolve it to produce a unit of intelligence that represents an approximation of a complex real-world concept. The training accomplished by gradual complexification of the topology of neural networks that are encoded into the genome of a synthetic intelligence unit. There can be several ANNs joined into the complex hierarchy of modules.","tags":["neuroevolution","reinforcement-learning","unsupervised-learning"],"title":"Neuroevolution","type":"post"},{"authors":["Iaroslav Omelianenko"],"categories":null,"content":"The full reference of the presented work is:\nOmelianenko, I (2017). Applying Deep Machine Learning for Psycho-Demographic Profiling of Internet Users using O.C.E.A.N. Model of Personality. Proceedings of the 2017 Future Technologies Conference (SAI) – IEEE, Vancouver, Canada, ISBN (USB) 978-1-5386-1744-1, pp. 375-384\n","date":1511991000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1511991000,"objectID":"2c0dbee07960f89b10257a61f8476b2d","permalink":"https://io42.space/talk/ftc2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/ftc2017/","section":"talk","summary":"I presented our research paper \\\"Applying Deep Machine Learning for Psycho-Demographic Profiling of Internet Users using O.C.E.A.N. Model of Personality\\\"","tags":["deep-learning","artificial-neural-networks","psycho-demographic profiling"],"title":"FTC 2017 paper presentation","type":"talk"},{"authors":["Iaroslav Omelianenko"],"categories":null,"content":"","date":1511991000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1511991000,"objectID":"e0ec60bde2a653d98ec3a5b1a1dbfd81","permalink":"https://io42.space/publication/ftc2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/ftc2017/","section":"publication","summary":"The project had a goal to provide the working implementation of psycho-demographic profiling algorithm, which can be used to profile Internet users based on digital footprints they leave by using various Internet services. We provide full source code implementation in the R programming language of the algorithms described in the corresponding research paper.","tags":["psycho-demographic profiling"],"title":"FTC 2017, Vancouver, Canada","type":"publication"},{"authors":null,"categories":null,"content":"This project had a goal to research if steady-state visually evoked potential (SSVEP) can be used to create Brain Hash Function Algorithm able to distinguish between unique footprints of each individual brain under specific visual stimulation with electro-physiological visual feedback based on consumer-grade EEG monitoring device.\nThe project scope consist of two major parts:\nImplementation of electro-physiological visual feedback system based on consumer-grade EEG monitoring device. It should perform monitoring of EEG signals in real time and perform preprocessing of received raw EEG signal.\nImplementation of advance machine-learning pipeline to automatically extract important features from data stream and perform classification of encoded features. It should perform confident classification of the collected EEG data in order to (a) reliably distinguish signal from noise and (b) reliably distinguish between EEG records collected from different human participants.\nThe project timeline and results can be found at: ResearchGate\n","date":1501773934,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501773934,"objectID":"e346f268f321ba8826e413e43f20bb65","permalink":"https://io42.space/project/brainhash/","publishdate":"2017-08-03T18:25:34+03:00","relpermalink":"/project/brainhash/","section":"project","summary":"Our goal is to create Brain Hash Algorithm able to produce robust distinction between EEG signals of different humans under electro-physiological visual feedback based on steady-state visually evoked potential (SSVEP). It can be applied at variety of tasks from user authentication at online web services to user identification for physical access control systems.","tags":["brain-computer-interface"],"title":"SSVEP Brain Hash Function","type":"project"},{"authors":["Iaroslav Omelianenko"],"categories":null,"content":"","date":1501770732,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501770732,"objectID":"18bef01e4b67d351d439b1eef8200438","permalink":"https://io42.space/publication/arxiv-1708.01167/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/arxiv-1708.01167/","section":"publication","summary":"In this article we present the results of our research related to the study of correlations between specific visual stimulation and the elicited brain's electro-physiological response collected by EEG sensors from a group of participants. We will look at how the various characteristics of visual stimulation affect the measured electro-physiological response of the brain and describe the optimal parameters found that elicit a steady-state visually evoked potential (SSVEP) in certain parts of the cerebral cortex where it can be reliably perceived by the electrode of the EEG device.","tags":["brain-computer interface"],"title":"arXiv:1708.01167","type":"publication"},{"authors":null,"categories":null,"content":"The project had a goal to provide working implementation of psycho-demographic profiling algorithm which can be used to profile Internet users based on digital footprints they leave by using various Internet services. We provide full source code implementation in R programming language of the algorithms described in corresponding research paper.\nWe have used variety of machine learning and data mining tools in order to process input data corpus and to create artificial neural networks for multivariate regression analysis.\n","date":1499271025,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499271025,"objectID":"4f75bbc72c28186574863362cabba490","permalink":"https://io42.space/project/psistats/","publishdate":"2017-07-05T19:10:25+03:00","relpermalink":"/project/psistats/","section":"project","summary":"The project had a goal to provide the working implementation of psycho-demographic profiling algorithm, which can be used to profile Internet users based on digital footprints they leave by using various Internet services. We provide full source code implementation in the R programming language of the algorithms described in the corresponding research paper.","tags":["psycho-demographic profiling"],"title":"Psistats","type":"project"},{"authors":["Iaroslav Omelianenko"],"categories":["artificial-neural-networks"],"content":"","date":1488878841,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1488878841,"objectID":"0a443518ff6a1f84b2906f0085c863c5","permalink":"https://io42.space/publication/arxiv-1703.06914/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/arxiv-1703.06914/","section":"publication","summary":"The project had a goal to provide the working implementation of psycho-demographic profiling algorithm, which can be used to profile Internet users based on digital footprints they leave by using various Internet services. We provide full source code implementation in the R programming language of the algorithms described in the corresponding research paper.","tags":["psycho-demographic profiling"],"title":"arXiv:1703.06914","type":"publication"}]