<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>reinforcement-learning on IO42 Learning to Learn</title>
    <link>/tags/reinforcement-learning/</link>
    <description>Recent content in reinforcement-learning on IO42 Learning to Learn</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Iaroslav Omelianenko</copyright>
    <lastBuildDate>Thu, 06 Sep 2018 14:44:19 +0300</lastBuildDate>
    
	<atom:link href="/tags/reinforcement-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Creation of Autonomous Artificial Intelligent Agents using Novelty Search method of fitness function optimization</title>
      <link>/post/creation-aaia-using-novelty-search/</link>
      <pubDate>Thu, 06 Sep 2018 14:44:19 +0300</pubDate>
      
      <guid>/post/creation-aaia-using-novelty-search/</guid>
      <description>For billions of years of evolution, biological intelligent agents have mastered the power to find optimal solutions in deceptive environments that we encounter in our daily interactions with the real world. We can easy navigate themselves through the maze of a big city subways and roadways. But for artificial intelligent systems, this is too difficult to be easily solved using the optimal computing resources. This is especially true for offline autonomous agents that are not backed by super power of cloud servers.</description>
    </item>
    
    <item>
      <title>RG.2.2.20698.80328</title>
      <link>/publication/rg.2.2.20698.80328/</link>
      <pubDate>Tue, 28 Aug 2018 15:28:14 +0200</pubDate>
      
      <guid>/publication/rg.2.2.20698.80328/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Go NEAT Novelty Search</title>
      <link>/project/goneat_ns/</link>
      <pubDate>Wed, 25 Jul 2018 18:30:58 +0300</pubDate>
      
      <guid>/project/goneat_ns/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Go NEAT</title>
      <link>/project/goneat/</link>
      <pubDate>Wed, 25 Jul 2018 17:55:31 +0300</pubDate>
      
      <guid>/project/goneat/</guid>
      <description>This project provides implementation of NeuroEvolution of Augmenting Topologies (NEAT) method written in Go language.
The Neuroevolution (NE) is an artificial evolution of Neural Networks (NN) using genetic algorithms in order to find optimal NN parameters and topology. Neuroevolution of NN may assume search for optimal weights of connections between NN nodes as well as search for optimal topology of resulting NN. The NEAT method implemented in this work do search for both: optimal connections weights and topology for given task (number of NN nodes per layer and their interconnections).</description>
    </item>
    
    <item>
      <title>Neuroevolution - Evolving Artificial Neural Networks Topology From the Scratch</title>
      <link>/post/neuroevolution-evolving-ann-topology-from-the-scratch/</link>
      <pubDate>Wed, 25 Jul 2018 13:55:17 +0300</pubDate>
      
      <guid>/post/neuroevolution-evolving-ann-topology-from-the-scratch/</guid>
      <description>The most popular method of Artificial Neural Networks (ANN) training - at the time of this essay writing - is to use some form of Gradient Descent (GD) combined with error back propagation w.r.t. objective function defining our learning goal. This methodology was invented about 30 years ago by Geoffrey Hinton and become a foundation of all modern research activities in the Deep Machine Learning (ML) and the Artificial Intelligence (AI).</description>
    </item>
    
  </channel>
</rss>