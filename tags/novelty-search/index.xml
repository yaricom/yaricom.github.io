<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>novelty-search | IO42 Learning to Learn</title>
    <link>https://io42.space/tags/novelty-search/</link>
      <atom:link href="https://io42.space/tags/novelty-search/index.xml" rel="self" type="application/rss+xml" />
    <description>novelty-search</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2024 Iaroslav Omelianenko</copyright><lastBuildDate>Thu, 04 Jul 2024 15:28:14 +0200</lastBuildDate>
    <image>
      <url>https://io42.space/img/portrait.jpg</url>
      <title>novelty-search</title>
      <link>https://io42.space/tags/novelty-search/</link>
    </image>
    
    <item>
      <title>Artificial swarm intelligence</title>
      <link>https://io42.space/publication/pci1028-0979-2024-3-7/</link>
      <pubDate>Thu, 04 Jul 2024 15:28:14 +0200</pubDate>
      <guid>https://io42.space/publication/pci1028-0979-2024-3-7/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Simulation of the Autonomous Maze Navigation using the NEAT Algorithm</title>
      <link>https://io42.space/publication/pp2023.04.076/</link>
      <pubDate>Fri, 01 Dec 2023 15:28:14 +0200</pubDate>
      <guid>https://io42.space/publication/pp2023.04.076/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Hands-On Neuroevolution With Python</title>
      <link>https://io42.space/publication/hands-on-neuroevolution-with-python/</link>
      <pubDate>Wed, 01 Jan 2020 17:38:33 +0200</pubDate>
      <guid>https://io42.space/publication/hands-on-neuroevolution-with-python/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Artificial Swarm Intelligence and Cooperative Robotic Systems</title>
      <link>https://io42.space/publication/preprints201901.0282/</link>
      <pubDate>Tue, 05 Feb 2019 15:05:37 +0200</pubDate>
      <guid>https://io42.space/publication/preprints201901.0282/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Creation of Autonomous Artificial Intelligent Agents using Novelty Search method of fitness function optimization</title>
      <link>https://io42.space/post/creation-aaia-using-novelty-search/</link>
      <pubDate>Thu, 06 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://io42.space/post/creation-aaia-using-novelty-search/</guid>
      <description>&lt;p&gt;For billions of years of evolution, biological intelligent agents have mastered the power to find optimal solutions in deceptive environments that we encounter in our daily interactions with the real world. We can easy navigate themselves through the maze of a big city subways and roadways. But for artificial intelligent systems, this is too difficult to be easily solved using the optimal computing resources. This is especially true for offline autonomous agents that are not backed by &lt;em&gt;super power of cloud servers&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The main problem here is related to the fact that reliable maze navigation requires the development of a solution in an environment having many traps with strong local optima of fitness function. Such traps are represented as cul-de-sacs that are close to the final destination, but that can not be escaped without a step back, away from the ultimate goal (at least temporary). In such environments, objective-based solvers basically can not find optimal solution or any solution at all, because they do not have the necessary internal machinery for committing the leap-of-faith and move backward from the target in order to eventually find a way out.&lt;/p&gt;
&lt;p&gt;The objective-based solvers depends on the best attempts of their designers to assess the operating environment and develop a better way to achieve the ultimate goal. But, as it happens in the real world, preliminary assumptions often can not account for all the traps on the way to the goal because of the extreme complexity of the environment settings. And even in simple artificial environments, such as maze navigation, it often happens that objective-based solvers can not find the optimal solution within the &lt;em&gt;adequate execution time and computational resources allocation&lt;/em&gt;. But for successful autonomous execution in real world environments, it is critically important to create Intelligent Agents capable of quickly finding a solution with minimal computational load.&lt;/p&gt;
&lt;h2 id=&#34;experiment-overview&#34;&gt;EXPERIMENT OVERVIEW&lt;/h2&gt;
&lt;p&gt;In the experiment we studied how Novelty Search (NS)&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; method of fitness function optimization performs compared to traditional objective-based ones for unsupervised training of Artificial Intelligent Agents to do spatial navigation in complex maze environment. The main idea behind NS optimization is to rather look for novel outcomes in the search space than the distance to the final objective: the maze exit. The Novelty Search assigns higher fitness values to the Intelligent Agent capable to find the most novel solution among all previous tries. Despite its ignorance to the final objective the NS happens to be extremely effective optimization method capable of breeding AAIA, which crack deceptive real-world tasks even in the realms where traditional objective-based methods have failed completely. The main assumption about what makes this possible, is that in order to reach final goal, AAIA must find several intermediate goals (stepping stones) which in most cases do not resemble the ultimate objective. Sometimes Intelligent Agent must step back to avoid deceptive traps. By doing this it will see a decrease in value of objective-based fitness function for a moment but will get a better outcomes in the future. This is one of the fundamental properties of the real-world environment that the exact route to the final objective in most cases can not be predicted in advance, and all intermediate stepping stones should be found by taking the path.&lt;/p&gt;
&lt;p&gt;The Novelty Search optimization seems like a natural fit for Neuro-evolution family of genetic algorithms producing elegant custom Artificial Neural Networks (ANNs). In the experiment we combined NS with Neuroevolution of Augmented Topologies algorithm&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; which efficiently evolve ANNs through complexification by augmenting its topologies.&lt;/p&gt;
&lt;p&gt;More details about NEAT algorithm implementation can be found in my previous article: ‘Neuroevolution — evolving Artificial Neural Networks topology from the scratch’&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h4 id=&#34;-the-maze-solver-agent-configuration&#34;&gt;&amp;gt; The Maze Solver Agent Configuration&lt;/h4&gt;
&lt;p&gt;Autonomous Artificial Intelligent Agent, designed to solve the maze, has ten input sensors that allow collecting information about the environment and two output effectors controlling its movements through the maze (see &lt;em&gt;Figure 1&lt;/em&gt;). The final objective of the agent is to go through the maze and find a way out.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;maze-agent.png&#34; data-caption=&#34;The configuration schema of the maze agent with input sensors plot&#34;&gt;
&lt;img data-src=&#34;maze-agent.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The configuration schema of the maze agent with input sensors plot
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The input sensors are: six range finders that indicate the distance to the nearest obstacle (blue arrows) and four pie-slice radar sensors (slices of red circle) that act as a compass towards the goal (maze exit), activating when a line from the goal to the center of the agent falls within the pie-slice. The green-yellow arrow in the center points to the movement direction of the agent.&lt;/p&gt;
&lt;p&gt;The agent is also equipped with two effectors producing a forces that respectively turn and propel the robot, i.e. change its linear and angular velocity.&lt;/p&gt;
&lt;h4 id=&#34;-seed-genome-configuration&#34;&gt;&amp;gt; Seed Genome Configuration&lt;/h4&gt;
&lt;p&gt;The configuration of the seed genome of the solver agent can be summarized as follows (see &lt;em&gt;Figure 2&lt;/em&gt;):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ten input (sensor) neurons (blue): six for range finders [RIGHT, FRONT-RIGHT, FRONT, FRONT-LEFT, LEFT, BACK] plus four for slice radar sensors with 45 degree FOV [FRONT, LEFT, BACK, RIGHT]&lt;/li&gt;
&lt;li&gt;two output (effectors) neurons (red): angular (neuron #13) and linear (neuron #14) velocity controlling effectors&lt;/li&gt;
&lt;li&gt;one hidden neuron (#12) to introduce non linearity (green)&lt;/li&gt;
&lt;li&gt;one bias neuron (#1) to avoid zero saturation when input neurons is not activated (yellow)&lt;/li&gt;
&lt;/ul&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;seed-genome.png&#34; data-caption=&#34;The seed genome configuration&#34;&gt;
&lt;img data-src=&#34;seed-genome.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The seed genome configuration
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The input neurons has following numbers on the diagram above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Range Finders: #2 — RIGHT, #3 — FRONT-RIGHT, #4 — FRONT, #5 — FRONT-LEFT, #6 — LEFT, #7 — BACK&lt;/li&gt;
&lt;li&gt;Radar Sensors: #8 — FRONT, #9 — LEFT, #10 — BACK, #11 — RIGHT&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;-the-novelty-search-metric-definition-for-a-maze-environment&#34;&gt;&amp;gt; The Novelty Search metric definition for a maze environment&lt;/h4&gt;
&lt;p&gt;The &lt;em&gt;Novelty Search optimization&lt;/em&gt; method is based on novelty metric calculation for each solver agent after performing a certain number of time steps in simulation of maze navigation for that agent. The novelty metric biases the search in a fundamentally different way than the &lt;em&gt;objective-based&lt;/em&gt; fitness function (which depends only on the distance from the agent to the exit) and determines the behavior-space through which the search will be performed. Therefore, since what is important in the maze, this is where the solving agent ends navigation, then for the maze domain, the behavior of a navigator is defined as &lt;em&gt;its final position&lt;/em&gt;. The novelty metric then maximizes the N-nearest neighbor distance&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; between the final positions of all known solving agents, i.e. the most distant agent will have the greatest score of the novelty metric.&lt;/p&gt;
&lt;p&gt;The effect of this novelty metric is to reward the solver agent for ending in a place where none have ended before and the method of traversal is ignored. This measure reflects that what is important, is to reach a certain location (i.e. the goal) rather than the method of locomotion. Thus, although the novelty metric has no knowledge of the ultimate goal, a solution that reaches the goal can appear novel. In addition, the comparison between fitness-based and novelty-based search is fair because both scores are calculated only based on the distance of the final position of the agent from other points.&lt;/p&gt;
&lt;h2 id=&#34;experiment-results&#34;&gt;EXPERIMENT RESULTS&lt;/h2&gt;
&lt;p&gt;As for deceptive environments we choose two types of maze environments with different complexity as was recommended in &lt;em&gt;this research&lt;/em&gt;&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;: medium and hard maze. The maze configurations was designed in such a way as to create many cul-de-sacs with strong local optima, deceiving the objective-based optimization methods.&lt;/p&gt;
&lt;h3 id=&#34;the-medium-complexity-maze-environment&#34;&gt;The Medium Complexity Maze Environment&lt;/h3&gt;
&lt;p&gt;The first experiment to establish baseline performance metric was performed using &lt;strong&gt;maze configuration of medium complexity&lt;/strong&gt;. The Novelty Search optimization was combined with Neuro-Evolution of Augmented Topologies algorithm which use genetic neuro-evolution process to create a population of organisms capable of solving a maze. We also compared its performance with the objective-based optimization method for the NEAT algorithm, where fitness function optimization was dependent on how close final destination of produced organism is from the exit of the maze.&lt;/p&gt;
&lt;p&gt;The final performance metric of each Autonomous Agent created for both optimization methods depends only on how close to the maze exit is the final destination of the solver after $400$ stimulation steps. Thus, despite the various methods of fitness function optimization, the final results can be compared for both methods. Each experimental trial was performed with $2000$ epochs of evolution or until a winner is found.&lt;/p&gt;
&lt;h4 id=&#34;-novelty-search-optimization&#34;&gt;&amp;gt; Novelty Search Optimization&lt;/h4&gt;
&lt;p&gt;Applying Novelty Search based optimization it was possible to get the winner in &lt;strong&gt;10 form 10&lt;/strong&gt; trials with optimal genome found approximately within $50$ generations. An Artificial Neural Network produced by an organism with a near optimal genome has $1$ neurons with only three hidden units, i.e. it was capable of growing two additional units compared to the above-mentioned seed genome (see &lt;a href=&#34;#seed-genome-configuration&#34;&gt;Figure 2&lt;/a&gt;). And it is able to control maze solver agent with a spatial error of about $1.9%$ for targeting the exit of the maze.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;medium-maze-NS-winner.png&#34; data-caption=&#34;The medium maze winner&amp;rsquo;s genome when Novelty Search optimization method applied&#34;&gt;
&lt;img data-src=&#34;medium-maze-NS-winner.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The medium maze winner&amp;rsquo;s genome when Novelty Search optimization method applied
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Among with the two additional hidden units (neurons), the recurrent link was developed at the output neuron #13 (&lt;em&gt;angular velocity effector&lt;/em&gt;) — see &lt;em&gt;Figure 3&lt;/em&gt;. The recurrent link at this output neuron appears to be of great importance, since it was introduced in each configuration of the winner’s genome generated in each test trial. Such a consistent pattern seems pretty reasonable for the neuron #13, because it affects the agent’s steering and requires learning more complicated behavior compared to the neuron #14 (&lt;em&gt;linear velocity control&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;It is also interesting to consider the hidden neuron #91, which seemingly have learned the complex behavior of the steering to the exit of the maze when it is discovered to the right or behind the agent. We&amp;rsquo;ve made such assumptions because of its connections with input sensors #2, #7 (range finders: RIGHT, BACK) and #10, #11 (radar sensors: BACK, RIGHT).&lt;/p&gt;
&lt;p&gt;The hidden neuron #293 connected with input sensor #11 (radar sensor: RIGHT), has learned to influence the steering of the agent in the direction of the exit of the maze, since most of the time the exit is on the right bottom relative to the agent.&lt;/p&gt;
&lt;p&gt;The hidden neuron #12 which is introduced in &lt;a href=&#34;#seed-genome-configuration&#34;&gt;seed genome&lt;/a&gt; operates as main control-and-relay switch relaying signals from sensors and other hidden neurons to the effectors (neurons #13, #14).&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;medium-maze-NS.png&#34; data-caption=&#34;The color coded final positions of NS maze solvers for medium maze environment&#34;&gt;
&lt;img data-src=&#34;medium-maze-NS.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The color coded final positions of NS maze solvers for medium maze environment
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;On the &lt;em&gt;Figure 4&lt;/em&gt; presented a diagram of the maze solving simulation by solver agents controlled by ANNs, derived from the genomes of all organisms introduced into the population until a winner is found. Agents are coded by color depending on which species the source organism belongs to. The fitness of agent is measured as the relative distance between its final destination and maze exit after running simulation for certain number of time steps (&lt;em&gt;$400$ in our setup&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;initial agent position is at the top-left corner&lt;/em&gt; marked with green circle and &lt;em&gt;maze exit at the bottom-right&lt;/em&gt; marked with red circle.&lt;/p&gt;
&lt;p&gt;The upper plot shows the final destinations of the most fit agents ($fitness &amp;gt;= 0.8$), and the lower plot - the rest. The results are presented for an experimental trial producing the configuration of the winner genome depicted at &lt;em&gt;Figure 3&lt;/em&gt;. The total number of species created at that trial is $32$, with only $8$ becoming the most fit ones ($fitness &amp;gt;= 0.8$).&lt;/p&gt;
&lt;h4 id=&#34;-objective-based-optimization&#34;&gt;&amp;gt; Objective-Based Optimization&lt;/h4&gt;
&lt;p&gt;Applying objective-based optimization, it was possible to create the winners capable of solving medium maze configuration in &lt;strong&gt;9 from 10&lt;/strong&gt; trials. But the configuration of the winner&amp;rsquo;s genome in most cases was not so elegant and energy efficient, as with above-mentioned Novelty Search optimization.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;medium-maze-objective-winner.png&#34; data-caption=&#34;The medium maze winner&amp;rsquo;s genome when objective-based fitness function optimization method applied&#34;&gt;
&lt;img data-src=&#34;medium-maze-objective-winner.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The medium maze winner&amp;rsquo;s genome when objective-based fitness function optimization method applied
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;After $248$ generations, it was found near optimal configuration of the winner&amp;rsquo;s genome (see &lt;em&gt;Figure 5&lt;/em&gt;), capable of guiding the maze solving agent through the medium-complexity maze and reach the exit of the maze with spatial error about $1.8%$. The artificial neural network produced by this genome has $22$ units (neurons) with nine hidden neurons for modeling complex learned behavior.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;medium-maze-objective.png&#34; data-caption=&#34;The color coded final positions of objective-based maze solvers for medium maze environment&#34;&gt;
&lt;img data-src=&#34;medium-maze-objective.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The color coded final positions of objective-based maze solvers for medium maze environment
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Comparing the objective-based simulation plot (&lt;em&gt;Figure 6&lt;/em&gt;) with the similar for simulation based on Novelty Search optimization, it can be seen that agents final destinations are distributed less evenly through the maze space. Another interesting point is that most fit agents were &lt;em&gt;less exploratory&lt;/em&gt;, moving mainly along the maze walls towards the local fitness optima. This behavior resulted in more generations needed to produce the winner on average, as well as completely failed trials.&lt;/p&gt;
&lt;h3 id=&#34;the-hard-complexity-maze-environment&#34;&gt;The Hard Complexity Maze Environment&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;hard maze configuration&lt;/strong&gt; introduces additional complexity, emphasizing the idiosyncrasies of the objective-based optimization method. This requires a bit of strategic thinking, which sometimes allows the agent to deviate from the seemingly optimal places (with high local fitness function values) to finally find the guiding path through the maze. The ability of Novelty Search optimization to mimic mentioned strategic reasoning due to its inherent ability to find all the promising areas of the search space has made it an absolute champion with this experiment.&lt;/p&gt;
&lt;h4 id=&#34;-novelty-search-optimization-1&#34;&gt;&amp;gt; Novelty Search Optimization&lt;/h4&gt;
&lt;p&gt;The &lt;em&gt;Novelty Search&lt;/em&gt; optimization method, produced solving agents capable to solve the hard maze in &lt;strong&gt;10 from 10&lt;/strong&gt; trials. The power of NS method led to the finding of winning solvers within up to $100$ generations in the maze environment of both: medium and hard complexity. Which marks NS as a highly effective optimization method for creating Autonomous Artificial Intelligent Agents capable of complex spatial navigation.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;hard-maze-NS-winner.png&#34; data-caption=&#34;The hard maze winner&amp;rsquo;s genome when Novelty Search optimization method applied&#34;&gt;
&lt;img data-src=&#34;hard-maze-NS-winner.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The hard maze winner&amp;rsquo;s genome when Novelty Search optimization method applied
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;After $109$ generations of populations of organisms, the near optimal configuration of the winner&amp;rsquo;s genome was found (see &lt;em&gt;Figure 7&lt;/em&gt;). The winner is able to guide the agent through the hard maze environment and approach the exit with a spatial error $2.5%$. The Artificial Neural Network produced by this genome has only $17$ units (neurons) with four hidden neurons for &lt;em&gt;modeling complex learned behavior&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;It is interesting to note that recurrent link on the output neuron #13 (angular velocity effector) was &lt;em&gt;routed through two hidden neurons&lt;/em&gt; compared with the medium maze, where the neuron #13 was simply linked to itself. This may result in more complex behavior learned, especially taking into account that link passes through the neuron #42, affected by the range finder: LEFT and the radar: BACK. The neuron #42 is also affected by connection to the neuron #643 (affected by the range finder: LEFT). As a result, we can assume that it learned how to steer the agent when the exit of the maze is behind, and the wall is on the left, i.e. follow the left wall, moving forward.&lt;/p&gt;
&lt;p&gt;Another important point to consider is about possible learned behavior encoded in the hidden neuron #297, which is affected by input range finder sensors detecting distance to obstacles in the RIGHT and FRONT direction. Considering the maze configuration, we can assume that this neuron learned to avoid the left chamber&amp;rsquo;s trap, where an extremely strong local maximum of the fitness function was introduced (based on the distance to the exit of the maze).&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;hard-maze-NS.png&#34; data-caption=&#34;The color coded final positions of NS maze solvers for hard maze environment&#34;&gt;
&lt;img data-src=&#34;hard-maze-NS.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The color coded final positions of NS maze solvers for hard maze environment
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Because of the inherent complexity of the hard maze environment, only one species from $35$ was able to beget genome with fitness greater than $0.8$. This genome is also the winner able to produce control ANN successfully guiding solver agent to the exit of the maze. But, as can be seen from the &lt;em&gt;Figure 8&lt;/em&gt;, there is a high probability that as the number of simulation steps increases, a larger number of species will be able to hit the fitness threshold ($0.8$).&lt;/p&gt;
&lt;h4 id=&#34;-objective-based-optimization-1&#34;&gt;&amp;gt; Objective-Based Optimization&lt;/h4&gt;
&lt;p&gt;The &lt;em&gt;objective-based&lt;/em&gt; fitness function optimization method &lt;em&gt;completely failed to create any successful solver agent within all 10 experiment trials&lt;/em&gt;. In some trials, it was able to create AAIAs, almost finding the exit of the maze, but it seems that many more simulation steps are required to eventually produce the winner genome, which makes it &lt;em&gt;too computationally expensive&lt;/em&gt;.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;hard-maze-objective.png&#34; data-caption=&#34;The color coded final positions of NS maze solvers for hard maze environment&#34;&gt;
&lt;img data-src=&#34;hard-maze-objective.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    The color coded final positions of NS maze solvers for hard maze environment
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The &lt;em&gt;Figure 9&lt;/em&gt; depicts the most successful trials of the hard maze solvers with objective-based optimization of the fitness function. Looking at it, it can be seen that most of the final destinations of the Intelligent Agents were trapped in deceptive cul-de-sacs, blocking them from further exploration of the maze environment search space.&lt;/p&gt;
&lt;h2 id=&#34;discussion&#34;&gt;DISCUSSION&lt;/h2&gt;
&lt;p&gt;As shown by our experimental data, the &lt;em&gt;Novelty Search method&lt;/em&gt; of fitness function optimization, when the fitness of the agent is based on the novelty of the solution that it was able to find, significantly outperforms traditional objective-based optimization and was even able to solve the navigation task when the traditional method failed completely.&lt;/p&gt;
&lt;p&gt;We believe that &lt;em&gt;Novelty Search optimization&lt;/em&gt; can be successfully applied to create optimal solving agents in many areas where strong deceptive local optima of fitness function prevents traditional objective-based methods from finding optimal or any solutions at all.&lt;/p&gt;
&lt;p&gt;The full source code of the experiment implemented in GoLang: &lt;a href=&#34;https://github.com/yaricom/goNEAT_NS&#34;&gt;https://github.com/yaricom/goNEAT_NS&lt;/a&gt;. Please refer to it for more details about experiment particulars.&lt;/p&gt;
&lt;p&gt;The associated research project can be found at ResearchGate: &lt;a href=&#34;https://www.researchgate.net/project/Novelty-Search-optimization-for-NeuroEvolution&#34;&gt;https://www.researchgate.net/project/Novelty-Search-optimization-for-NeuroEvolution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The author&amp;rsquo;s NEAT algorithm implementation in the GO language is also shared through NEAT software catalog, hosted by Evolutionary Complexity (EPlex) Research Group at the University of Central Florida: &lt;a href=&#34;http://eplex.cs.ucf.edu/neat_software/&#34;&gt;http://eplex.cs.ucf.edu/neat_software/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Special thanks to &lt;a href=&#34;http://www.cs.ucf.edu/~kstanley/&#34;&gt;Dr. Kenneth O. Stanley&lt;/a&gt; for advises and sharing the NEAT algorithm details.&lt;/p&gt;
&lt;h2 id=&#34;future-work&#34;&gt;FUTURE WORK&lt;/h2&gt;
&lt;p&gt;We consider the development of modular AI systems based on ensembles of highly optimized compact Neural Networks. Our goal is to create compact utility NN blocks that are trained to represent vocabulary of the real-world terms that can be combined to form complex knowledge and skill sets. The mentioned NN blocks will be created using neuro-evolutionary algorithms by the method of gradual complexification, creating small and energy-efficient NN topologies that can be executed on a commodity CPUs with minimal power consumption. We call these blocks as &lt;em&gt;Term Artificial Neural Network (&lt;strong&gt;tANN&lt;/strong&gt;)&lt;/em&gt; to emphasize the fact that each NN block represents a specific term in our custom real-world vocabulary.&lt;/p&gt;
&lt;p&gt;In addition, in order to model a more complex behavior, the &lt;em&gt;Supervisor ANN (&lt;strong&gt;sANN&lt;/strong&gt;)&lt;/em&gt; structure will be created to process the output of the tANN units and combine them with a common knowledge of the internal functions of the supervised process or system component.&lt;/p&gt;
&lt;p&gt;It is assumed that Autonomous Artificial Intelligent system will be represented in the form of a complex hierarchy of &lt;em&gt;tANN&lt;/em&gt; and &lt;em&gt;sANN&lt;/em&gt; blocks in combination. Where each block or hierarchy of blocks will be responsible for a particular function, knowledge unit or set of the system skills. Such a modular / hierarchical approach provides a simple means to increase system capacity by introducing additional blocks with specific training. It is also possible to obtain an understanding of the flow of AI system reasoning, following the activations of its constituent blocks. The knowledge transfer also becomes easier by simply taking a NN block trained for a specific vocabulary term and introducing it into the new system.&lt;/p&gt;
&lt;h4 id=&#34;-our-roadmap-for-future-research&#34;&gt;&amp;gt; Our roadmap for future research&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Creating definitions of the basic vocabulary terms&lt;/li&gt;
&lt;li&gt;Creation of configurations of the seed genomes for each specific term of the vocabulary&lt;/li&gt;
&lt;li&gt;Training / breeding of tANN structures from the vocabulary&lt;/li&gt;
&lt;li&gt;Experiments on training / breeding of sANN-structures, capable of solving specific complex problems&lt;/li&gt;
&lt;li&gt;Comparison of the performance of AI agents obtained using the described modular architecture against AI agents trained through traditional methods deep learning methods&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;references&#34;&gt;References:&lt;/h2&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;Joel Lehman and Kenneth O. Stanley, &lt;a href=&#34;http://eplex.cs.ucf.edu/papers/lehman_gptp11.pdf&#34;&gt;Novelty Search and the Problem with Objectives&lt;/a&gt;, Genetic Programming: Theory and Practice IX (GPTP 2011), New York, NY: Springer, 2011&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;Kenneth O. Stanley, &lt;a href=&#34;http://nn.cs.utexas.edu/keyword?stanley:phd04&#34;&gt;Ph.D. Dissertation: EFFICIENT EVOLUTION OF NEURAL NETWORKS THROUGH COMPLEXIFICATION&lt;/a&gt;, Department of Computer Sciences, The University of Texas at Austin, Technical Report~AI-TR-04–39, August 2004&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;Iaroslav Omelianenko, &lt;a href=&#34;https://medium.com/@io42/neuroevolution-evolving-artificial-neural-networks-topology-from-the-scratch-d1ebc5540d84&#34;&gt;Neuroevolution — evolving Artificial Neural Networks topology from the scratch&lt;/a&gt;, Medium, 2018&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;Donald E. Knuth, (1997) The Art of Computer Programming, Volume 1: Fundamental Algorithms Third Edition (Reading, Massachusetts: Addison-Wesley, 1997), xx+650pp. ISBN 0-201-89683-4&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;
&lt;p&gt;Joel Lehman, &lt;a href=&#34;http://joellehman.com/lehman-dissertation.pdf&#34;&gt;Evolution through the search for novelty&lt;/a&gt;, B.S. Ohio State University, 2007&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Creation of Autonomous Artificial Intelligent Agents using Novelty Search method of fitness function optimization</title>
      <link>https://io42.space/publication/rg.2.2.20698.80328/</link>
      <pubDate>Tue, 28 Aug 2018 15:28:14 +0200</pubDate>
      <guid>https://io42.space/publication/rg.2.2.20698.80328/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Self Replication to Preserve Innate Learned Structures in Artificial Neural Networks</title>
      <link>https://io42.space/post/self-replication-to-preserve-innate-learned-structures-in-ann/</link>
      <pubDate>Fri, 27 Jul 2018 18:57:35 +0300</pubDate>
      <guid>https://io42.space/post/self-replication-to-preserve-innate-learned-structures-in-ann/</guid>
      <description>&lt;p&gt;It’s interesting to investigate combination of deep &lt;a href=&#34;https://medium.com/@io42/neuroevolution-evolving-artificial-neural-networks-topology-from-the-scratch-d1ebc5540d84&#34;&gt;neuro-evolution&lt;/a&gt; and self-replication&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; to evolve Artificial Neural Networks (ANNs) able to keep and complexify innate learned structures aimed to fulfill auxiliary tasks (orthogonal to the self-replication).&lt;/p&gt;
&lt;p&gt;In such a way, it may became possible to build &lt;em&gt;evolutionary lineage tree&lt;/em&gt; of ANNs specialized to complete specific tasks under different environmental settings through subsequent training sessions. And the knowledge acquired during all these training sessions will accumulate not only in the form of learned connections’ weights, but in a neural network’s &lt;em&gt;topology&lt;/em&gt; as well.&lt;/p&gt;
&lt;p&gt;Subsequently, with appropriate orchestration of resulting intelligent agents it can be possible to produce swarm intelligence with much higher order of complexity than of each individual agent, able to adequately solve imperfect knowledge problems through weighted consensus among all participants.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Biological life began with the first self-replicator, and natural selection kicked in to favor organisms that are better at replication, resulting in a self- improving mechanism. Analogously, we can construct a self-improving mechanism for artificial intelligence via natural selection, if AI agents had the ability to replicate and improve themselves without additional machinery.&lt;/em&gt;&lt;sup id=&#34;fnref1:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Numerous recent studies have shown that various brain structures include &lt;em&gt;innate knowledge seeds&lt;/em&gt; that explode into inalienable abilities of living organisms to learn or complete specific tasks right from the first seconds of immediate life experience.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Over 90% of our genes are expressed in the development of the brain, and a significant number of those are expressed selectively, in a way that allows the brain to self-assemble, even, to some non-trivial degree in the absence of experience. Mechanisms such as cell division, cell differentiation, cell migration, cell death, and axon guidance combine to self-assemble a rich first draft of the human brain, even prior to experience. Even in the absence of synaptic transmission, the primary mechanism by which experience is conveyed to the brain, the basic structure of the newborn brain is preserved.&lt;/em&gt;&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This demonstrates that different brain structures can be regarded to some extent as a swarm of intelligent agents that effectively combine weighted responses from different regions, from cortex to amygdala, in order to build an adequate complex response on the external stimuli created by the environment. It is also worth noting that different human brain structures was inherited from earlier inhuman forms of life, and we even have brain structures related to prehistoric reptiles. Thus, the development of innate brain structures can be regarded as a long-term evolutionary process of complexification from the most basic structures controlling autonomic peripheral neural system to the most complex structures supporting abstract reasoning. Such kind of increasing complexification allows evolution not to get stuck on local optima and to develop even more complex self-organizing structures through &lt;em&gt;dissipative adaptation&lt;/em&gt;&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Life manages to squeeze exquisite reliability in behaviour on large scales from a jittery herd of individual molecules, without always needing to put each atom in its place, and we might therefore feel encouraged to attempt something similar in our own feats of engineering.&lt;/em&gt;&lt;sup id=&#34;fnref1:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This point of view allows us to consider the evolution of synthetic intelligence in a similar way. The main idea is to simulate the process of natural selection that influences evolution of the life forms, by creating of specific &lt;em&gt;multi-staged environment&lt;/em&gt; that force neuro-evolution to generate highly specialized ANNs that can survive as a swarm. The training multi-stage environment must produce multiple challenges with increasing survival pressure. The key point here is the creation at each stage of an environmental challenge with ever increasing amount of available training signals. This will allow to evolve intelligent systems with innate knowledge of environment from it’s most basic form to a comprehensive understanding of the whole. The search for an evolutionary champion at each training stage can be carried out using a &lt;em&gt;novelty search&lt;/em&gt;&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; method that allows to explore all available survival options and to find the best fit among them.&lt;/p&gt;
&lt;p&gt;By combining orthogonal goals such as self-replication and survival in an increasingly complex environment, it’s possible to create adaptive pressure on the ANN’s evolutionary tree that will ignite the generation of complex systems with innate structures, capable to quickly learn new properties of the environment from the first moments of direct experience. As an added bonus, it will also sustain life-long learning of produced intelligent systems, by effectively incorporating new experiences into innate structures.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Self-replication involves a degree of introspection and self-awareness, which is helpful for lifelong learning and potential discovery of new neural network architectures.&lt;/em&gt;&lt;sup id=&#34;fnref2:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The resulting swarm of intelligent agents can become a foundation for creation of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Artificial_general_intelligence&#34;&gt;Artificial General Intelligence&lt;/a&gt; (AGI) with innate structures that allow to generalize knowledge about new experiences and environmental challenges.&lt;/p&gt;
&lt;p&gt;~&lt;/p&gt;
&lt;p&gt;The repost of the original article posted by author at Medium: &lt;a href=&#34;https://medium.com/@io42/self-replication-to-preserve-innate-leaned-structures-in-artificial-neural-networks-9bd8758662b4&#34;&gt;Self-replication to preserve innate learned structures in Artificial Neural Networks&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;references-1234567&#34;&gt;References: &lt;sup id=&#34;fnref3:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref1:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref2:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref1:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;&lt;/h2&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;Oscar Chang, Hod Lipson, &lt;a href=&#34;https://arxiv.org/abs/1803.05859&#34;&gt;Neural Network Quine&lt;/a&gt;, arXiv preprint: 1803.05859v3, 2018&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref2:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref3:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;Gary Marcus, &lt;a href=&#34;https://arxiv.org/abs/1801.05667&#34;&gt;Innateness, AlphaZero, and Artificial Intelligence&lt;/a&gt;, arXiv preprint: 1801.05667v1, 2018&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;Jeremy L. England, &lt;a href=&#34;https://www.englandlab.com/uploads/7/8/0/3/7803054/nnano.2015.250__1_.pdf&#34;&gt;Dissipative adaptation in driven self-assembly&lt;/a&gt;, Nature Nanotechnology volume 10, pages 919–923, 2015&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref2:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;Joel Lehman, &lt;a href=&#34;http://joellehman.com/lehman-dissertation.pdf&#34;&gt;Evolution through the search for novelty&lt;/a&gt;, B.S. Ohio State University, 2007&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;
&lt;p&gt;Robert Marsland III, Jeremy L. England, &lt;a href=&#34;https://arxiv.org/abs/1711.02172&#34;&gt;Speed, strength and dissipation in biological self-assembly&lt;/a&gt;, arXiv preprint: 1711.02172v1, 2017&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34;&gt;
&lt;p&gt;Sumantra Sarkar, Bin Wang, Jeremy L. England, &lt;a href=&#34;https://arxiv.org/abs/1709.09191&#34;&gt;Design of conditions for emergence of self-replicators&lt;/a&gt;, arXiv preprint: 1709.09191v2, 2018&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34;&gt;
&lt;p&gt;Iaroslav Omelianenko, &lt;a href=&#34;https://medium.com/@io42/neuroevolution-evolving-artificial-neural-networks-topology-from-the-scratch-d1ebc5540d84&#34;&gt;Neuroevolution — evolving Artificial Neural Networks topology from the scratch&lt;/a&gt;, Medium, 2018&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>GO NEAT Novelty Search</title>
      <link>https://io42.space/project/goneat_ns/</link>
      <pubDate>Wed, 25 Jul 2018 18:30:58 +0300</pubDate>
      <guid>https://io42.space/project/goneat_ns/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
